{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "ZTO9S2cpgnY3",
        "Du-l8sqUgzO0",
        "B8i6XIcdzn0h",
        "i4Na6kbZTCKS",
        "YKxKin0VCgD3",
        "XiQPmn2yCVHX",
        "rYsLfyUEGN0Q",
        "S3n8WDGP8eI2",
        "DDiI988DBvLd",
        "fNF1yFOsLWDf",
        "W6GM2drJpjkE",
        "Psem-fenpmry",
        "xRflnWg3prbQ",
        "5KXLcgM1nZsv",
        "oqh1eeROpY-3",
        "vITcG6e9qxsW",
        "5YAMdz21odZe",
        "x2YujLg5g8cl",
        "VX0X_rquqiPC",
        "YD5c4tDgKkfv"
      ],
      "authorship_tag": "ABX9TyODx06PKF1Hy69VDnAtKTup",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ellolo/cthulhu_fine_tuning/blob/main/5_evaluation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# System evaluation\n",
        "\n",
        "This Notebook contains code to evaluate several LLM-based systems on the task of answering 50 questions regarding the content of the Chtulhu Rulebook.\n",
        "The questions are created manually, together with their expected best answer.\n",
        "\n",
        "## Evaluation dataset\n",
        "I evaluate the systems on a dataset of 50 Question Answering (QA) pairs manually derived from the Chtulhu Rulebook. The dataset reflects typical questions that a player could ask about the game, and varies from questions that require a precise answer to open-eneded questions that require the system to reason and summarize the content of the book. The answers provided in the dataset are our gold standard to evaluate the systems.\n",
        "\n",
        "Examples:\n",
        "\n",
        "```\n",
        "{'question': 'Who wrote the Necronomicon chapter?',\n",
        " 'answer': 'Keith Herber',\n",
        " 'chapter': 1}\n",
        "\n",
        "{'question': 'Can you provide a short description of how a Chase takes place',\n",
        " 'answer': 'A chase take place when the participants have an escape route. The Keeper positions the participants, decided the order of play and how many movements each participant can make in each turn. At the beginning each participant makes a CON roll to adjust their MOV rating. Then, at each round of the chase the participants act in DEX order, and move a number of locations based on their MOV rating. In some cases attacks can also be performed. The Keeper can add hazards and barriers to the chase as well.',\n",
        " 'chapter': 7}\n",
        "```\n",
        "\n",
        "## Evaluation metrics\n",
        "\n",
        "Each answer in manually evaluated on three metrics:\n",
        "- **Correctness**: how closely the generated text answers the question at hand.\n",
        "- **Topicality**: how close the generated text is to the topic of the question at hand.\n",
        "- **Fluency**: how natural and grammatically correct the generated text is.\n",
        "\n",
        "For each metric a score from 1 to 5 is assigned, where 5 is best and 1 is worst.\n",
        "To compare the systems, I take the average of the scores across all questions.\n",
        "Plese refer to README file for more details on the evaluation metrics and dataset.\n",
        "\n",
        "## Evaluated systems\n",
        "\n",
        "I evaluated the following models:\n",
        "\n",
        "- **base models**: `Llama-3.1-8B-Instruct` and `Llama-3.2-1B-Instruct`\n",
        "- **LoRA QA fine-tuning**: LoRA adapters on top of a base model, fine-tuned using a QA dataset derived from the Chtulhu Rulebook. The code for to generate this system is in `2_lora_qa_finetuning.ipynb`.\n",
        "- **LoRA continued pretraining**: LoRA adapters on top of a base model, trained on the raw text extracted from the Chtulhu Rulebook. The code for to generate this system is in `3_lora_cont_pretraining.ipynb`.\n",
        "- **LoRA combined training**: LoRA adapters on top of a base model, trained on a dataset consisting of both the raw text and a sample of 2,000 QA pairs from the QA dataset. The code for to generate this system is in `4_lora_combined_training.ipynb`.\n",
        "- **LoRA stacked**: LoRA QA and Continued Pretraining adapters stacked on each other, i.e. we sum their weights.\n",
        "- **Vanilla RAG**: A simple RAG agent provided with Cthulhu Rulebook as knowledge base and using the base model as LLM.\n",
        "- **RAG with LoRA**: A simple RAG agent provided with Cthulhu Rulebook as knowledge base and using LoRA adapters on top of the base model as LLM.\n",
        "\n",
        "## Code in this Notebook\n",
        "\n",
        "The notebook contains the following code:\n",
        "\n",
        "- **Section 1,2**: Installs dependencies and load evaluation dataset\n",
        "- **Section 3**: Implements helper functions to run a system over the evaluation dataset and generate answers\n",
        "- **Section 4,5**: Loads base language model and runs it on the dataset to generate answers\n",
        "- **Section 6**: Loads system based on single LoRa adapters and runs them on the dataset  to generate answers\n",
        "- **Section 7**: Loads system based on stacked LoRa adapters and runs them on the dataset to generate answers\n",
        "- **Section 8, 9**: Sets-up RAG systems and runs them on the dataset to generate answers\n",
        "- **Section 10**: Puts together all generated answers of all system in a single file that will be used for manual evaluation.\n",
        "- **Section 11**: After manual annotation is completed, reads back the annotation file and computes metrics for all systems.\n",
        "\n"
      ],
      "metadata": {
        "id": "7u12w1ZJgrme"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Install dependencies and clone github repo"
      ],
      "metadata": {
        "id": "ZTO9S2cpgnY3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "jfJIkVkxF2yZ",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "! pip install -U 'transformers[torch]' datasets bitsandbytes peft evaluate rouge_score langchain langchain-huggingface langchain-community sentence-transformers faiss-gpu-cu12 #faiss-cpu\n",
        "!pip install numpy==1.26.4 --force-reinstall"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get HF token from secrets and login in HF hub, so that we can download models from HF Hub\n",
        "\n",
        "from huggingface_hub import login\n",
        "from google.colab import userdata\n",
        "\n",
        "HF_TOKEN=userdata.get('HF_TOKEN')\n",
        "if HF_TOKEN:\n",
        "  login(HF_TOKEN)\n",
        "else:\n",
        "  login()"
      ],
      "metadata": {
        "id": "Xuie9mo8GNdM"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone github repository.\n",
        "\n",
        "# Past here the SSH key stored on my personal laptopat: ~/dev/llm_cthulhu_fine_tuning/keys\n",
        "# This is not safe, but unfortunaly using Colab secrets did not work.\n",
        "\n",
        "! mkdir -p /root/.ssh\n",
        "with open(\"/root/.ssh/id_rsa\", mode=\"w\") as fp:\n",
        "    fp.write(\"\"\"<YOUR SSH KEY TO THE REPO>\"\"\")\n",
        "\n",
        "# <COPY FROM LOCAL DISK AT: ~/dev/llm_cthulhu_fine_tuning/keys>\n",
        "! ssh-keyscan -t rsa github.com >> ~/.ssh/known_hosts\n",
        "! chmod go-rwx /root/.ssh/id_rsa\n",
        "! git clone git@github.com:ellolo/cthulhu_fine_tuning.git"
      ],
      "metadata": {
        "id": "cAii6jm5GN_L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Load evaluation dataset\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Du-l8sqUgzO0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "dataset_file = \"evaluation/evaluation-dataset/cthulhu_eval_dataset.csv\"\n",
        "\n",
        "%cd /content/cthulhu_fine_tuning"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ExKgFn2REMV",
        "outputId": "286e1e07-5c7d-4360-fed4-1f526f9d8ec0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/cthulhu_fine_tuning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load evaluation dataset\n",
        "\n",
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"csv\", data_files=dataset_file, split=\"train\")\n",
        "dataset[0]"
      ],
      "metadata": {
        "id": "Vz-GNrm9SAsM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Define Helper functions\n",
        "\n",
        "Helper functions to generate answers for the questions in the evaluation dataset using a target model, and pushing these results in github."
      ],
      "metadata": {
        "id": "B8i6XIcdzn0h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# helper functions for evaluation\n",
        "\n",
        "# system prompt used for all systems (excluding rag)\n",
        "DEFAULT_SYSTEM_PROMPT = \"You are a helpful AI assistant.\"\n",
        "\n",
        "# system prompt used for rag systems\n",
        "DEFAULT_SYSTEM_PROMPT_RAG = (\n",
        " \"Using the information contained in the context, give a comprehensive answer \"\n",
        " \"to the question. \"\n",
        " \"Respond only to the question asked, response should be concise and relevant \"\n",
        " \"to the question. \"\n",
        " \"Provide the number of the source document when relevant. \"\n",
        " \"If the answer cannot be deduced from the context, do not give an answer. \"\n",
        ")\n",
        "\n",
        "from dataclasses import dataclass\n",
        "\n",
        "@dataclass\n",
        "class Adapter:\n",
        "  name: str\n",
        "  subfolder: str\n",
        "\n",
        "  @property\n",
        "  def shortname(self):\n",
        "    return self.name.replace(\".\", \"_\")\n",
        "\n",
        "\n",
        "def generate(model, system_prompt, user_prompt, temperature=0.1, greedy=False):\n",
        "  \"\"\"\n",
        "  Generates text from a language model given a system prompt and user prompt.\n",
        "\n",
        "  The input context provided to the language model is in chatml format, where\n",
        "  the first message is a system message with the system prompt, and the second\n",
        "  message is a user message with the user prompt.\n",
        "\n",
        "  Args:\n",
        "    model: The language model to use for generation.\n",
        "    system_prompt: The system prompt to provide to the model.\n",
        "    user_prompt: The user prompt to provide to the model.\n",
        "    temperature: The temperature for text generation (default is 0.1).\n",
        "    greedy: Whether to use greedy decoding (default is False).\n",
        "\n",
        "  Returns:\n",
        "    The generated text as a string.\n",
        "  \"\"\"\n",
        "  # format to chatml\n",
        "  chat = [\n",
        "      {\"role\": \"system\", \"content\": f\"{system_prompt}\"},\n",
        "      {\"role\": \"user\", \"content\": f\"{user_prompt}\"}\n",
        "  ]\n",
        "  chatml = tokenizer.apply_chat_template(\n",
        "      chat,\n",
        "      tokenize = False,\n",
        "      add_generation_prompt = True\n",
        "  )\n",
        "\n",
        "  # tokenize\n",
        "  inputs = tokenizer(chatml, return_tensors=\"pt\").to(device)\n",
        "  prompt_length = inputs['input_ids'].shape[1]\n",
        "\n",
        "  # generate tokens\n",
        "  with torch.no_grad():\n",
        "    if greedy:\n",
        "      # greedy generation\n",
        "      output_ids = model.generate(**inputs, max_new_tokens = 256, do_sample = False, pad_token_id=tokenizer.pad_token_id)\n",
        "    else:\n",
        "      # multinomial sampling generation\n",
        "      output_ids = model.generate(**inputs, max_new_tokens = 256, temperature = temperature, pad_token_id=tokenizer.pad_token_id)\n",
        "\n",
        "  # decode generated tokens into text\n",
        "  output_text = tokenizer.decode(output_ids[0][prompt_length:], skip_special_tokens=True) # remove input prompt from output (https://discuss.huggingface.co/t/generate-returns-full-prompt-plus-answer/70453)\n",
        "  return output_text\n",
        "\n",
        "\n",
        "def answer_question(model, example, temperature=0.1, greedy=False, system_prompt=None):\n",
        "    \"\"\"\n",
        "    Answers a question using a language model.\n",
        "\n",
        "    Args:\n",
        "      model: The language model to use for generation.\n",
        "      example: A dictionary containing the input data, expected to have a \"question\" key.\n",
        "      temperature: The temperature for text generation (default is 0.1).\n",
        "      greedy: Whether to use greedy decoding (default is False).\n",
        "      system_prompt: A system prompt to use for the model (default is DEFAULT_SYSTEM_PROMPT).\n",
        "\n",
        "    Returns:\n",
        "      The generated answer as a string.\n",
        "    \"\"\"\n",
        "    if not system_prompt:\n",
        "      system_prompt = DEFAULT_SYSTEM_PROMPT\n",
        "    user_prompt = f\"{example['question']}\"\n",
        "    return generate(model, system_prompt, user_prompt, temperature=temperature, greedy=greedy)\n",
        "\n",
        "\n",
        "def evaluate_model(model, dataset, temperature=0.1, greedy=False, system_prompt=None):\n",
        "  \"\"\"\n",
        "  Generates answers for all questions in a dataset using a given language model.\n",
        "\n",
        "  Args:\n",
        "    model: The language model to use for generation.\n",
        "    dataset: A Hugging Face Dataset object, containing the questions in the field \"question\".\n",
        "    temperature: The temperature for text generation (default is 0.1).\n",
        "    greedy: Whether to use greedy decoding (default is False).\n",
        "    system_prompt: A system prompt to use for the model (default is DEFAULT_SYSTEM_PROMPT).\n",
        "\n",
        "  Returns:\n",
        "    A Hugging Face Dataset object with an added \"generated_answer\" column containing the generated answers.\n",
        "  \"\"\"\n",
        "  generated_texts = []\n",
        "  for ct, example in enumerate(dataset):\n",
        "    print(f\"Generating answer {ct+1}/{len(dataset)}\")\n",
        "    generated_text = answer_question(model, example, temperature=temperature, greedy=greedy, system_prompt=system_prompt)\n",
        "    generated_texts.append(generated_text)\n",
        "  return dataset.add_column(\"generated_answer\", generated_texts)\n",
        "\n",
        "\n",
        "def answer_question_rag(model, example, rag_store, temperature=0.1, greedy=False, system_prompt=None):\n",
        "    \"\"\"\n",
        "    Answers a question using a RAG approach with a language model.\n",
        "\n",
        "    Args:\n",
        "      model: The language model to use for generation.\n",
        "      example: A dictionary containing the input data, expected to have a \"question\" key.\n",
        "      rag_store: The RAG store containing relevant documents.\n",
        "      temperature: The temperature for text generation (default is 0.1).\n",
        "      greedy: Whether to use greedy decoding (default is False).\n",
        "      system_prompt: A system prompt to use for the model (default is DEFAULT_SYSTEM_PROMPT_RAG).\n",
        "\n",
        "    Returns:\n",
        "      A tuple containing the generated answer as a string and a list of the top RAG documents used.\n",
        "    \"\"\"\n",
        "    if not system_prompt:\n",
        "      system_prompt = DEFAULT_SYSTEM_PROMPT_RAG\n",
        "    top_chunks = rag_store.similarity_search(example[\"question\"], k=5)\n",
        "    rag_context = \"\\nExtracted documents:\\n\\n\"\n",
        "    rag_context += \"\\n\\n\".join([f\"Document {str(i)}:::\\n\" + doc.page_content for i, doc in enumerate(top_chunks)])\n",
        "    user_prompt = (\n",
        "        \"Context:\\n\"\n",
        "        f\"{rag_context}\\n\"\n",
        "        \"---\\n\"\n",
        "        \"Here below is the question you need to answer.\\n\"\n",
        "        f\"Question: {example['question']}\"\n",
        "    )\n",
        "    output_text = generate(model, system_prompt, user_prompt, temperature=temperature, greedy=greedy)\n",
        "    return (output_text, [doc.page_content for doc in top_chunks])\n",
        "\n",
        "\n",
        "def evaluate_model_rag(model, dataset, rag_store, temperature=0.1, greedy=False, system_prompt=None):\n",
        "  \"\"\"\n",
        "  Generates answers for all questions in a dataset using a RAG approach with a given language model.\n",
        "\n",
        "  Args:\n",
        "    model: The language model to use for generation.\n",
        "    dataset: A Hugging Face Dataset object, containing the questions in the field \"question\".\n",
        "    rag_store: The RAG store containing relevant documents.\n",
        "    temperature: The temperature for text generation (default is 0.1).\n",
        "    greedy: Whether to use greedy decoding (default is False).\n",
        "    system_prompt: A system prompt to use for the model (default is DEFAULT_SYSTEM_PROMPT_RAG).\n",
        "\n",
        "  Returns:\n",
        "    A Hugging Face Dataset object with added \"generated_answer\" and \"rag_top_docs\" columns,\n",
        "    containing the generated answers and the list of the top RAG documents used for the answers.\n",
        "  \"\"\"\n",
        "  generated_texts = []\n",
        "  rag_results = []\n",
        "  for ct, example in enumerate(dataset):\n",
        "    print(f\"Generating answer {ct+1}/{len(dataset)}\")\n",
        "    generated_text, rag_result = answer_question_rag(model, example, rag_store, temperature=temperature, greedy=greedy, system_prompt=system_prompt)\n",
        "    generated_texts.append(generated_text)\n",
        "    rag_results.append(\"\\n==========\\n\".join(rag_result))\n",
        "  return dataset.add_column(\"generated_answer\", generated_texts).add_column(\"rag_top_docs\", rag_results)\n",
        "\n",
        "\n",
        "def push_results_to_git(dataset_with_answers, adapter: Adapter, system_prompt=None, quantized_model=False):\n",
        "  \"\"\"\n",
        "  Pushes evaluation results to the git repository.\n",
        "\n",
        "  Args:\n",
        "    dataset_with_answers: A Hugging Face Dataset object containing the generated answers.\n",
        "    adapter: An Adapter object containing the adapter name and subfolder.\n",
        "    system_prompt: The system prompt used for generation (optional).\n",
        "    quantized_model: A boolean indicating if the model was quantized (default is False).\n",
        "  \"\"\"\n",
        "\n",
        "  output_file_name = adapter.name + \"-\" + adapter.subfolder\n",
        "\n",
        "  if not system_prompt:\n",
        "    system_prompt = DEFAULT_SYSTEM_PROMPT\n",
        "\n",
        "  if system_prompt != DEFAULT_SYSTEM_PROMPT:\n",
        "    output_file_name = output_file_name + \"_prompt_\" + str(hash(system_prompt)% 10**6)\n",
        "\n",
        "  if quantized_model:\n",
        "    output_file = f\"evaluation/evaluation-results-quantized/res_{output_file_name}.csv\"\n",
        "  else:\n",
        "    output_file = f\"evaluation/evaluation-results/res_{output_file_name}.csv\"\n",
        "\n",
        "  dataset_with_answers.add_column(\"system_prompt\", [system_prompt for _ in range(len(dataset_with_answers))]) \\\n",
        "    .to_csv(output_file)\n",
        "\n",
        "  ! git config --global user.email \"marco.pennacchiotti@gmail.com\"\n",
        "  ! git add {output_file}\n",
        "  ! git commit -m \"added generated answers\"\n",
        "  ! git push origin main"
      ],
      "metadata": {
        "id": "Z-hV9aecnaqN"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Load base model\n",
        "\n",
        "Load the base model to which we will attach the Lora adapters that we want to evaluate.\n",
        "\n",
        "I load either `Llama-3.1-8B-Instruct` or `Llama-3.2-1B-Instruct`, since we have tuned adapters for both these base models\n",
        "\n",
        "I experimented with two versions of the base models:\n",
        "- **with quantization**: \\\\\n",
        "I used the same quantization used during fine-tuning of the adapter. This saves memory and ensures that the setup is consistent with the fine-tuning setup.\n",
        "- **without quantization**: \\\\\n",
        "I experimented also with the non-quantized base model, to tackle an issue emerging when using stacked adapters. Specifically, when the first adapter of the stack is merged to the base mode using `merge_and_unload()` and the base model is quantized, we see that the results are not the same as simply applying the adapter on top of the base model. When instead we use the base model without quantization, we get the same results as expected. According to Hugging Face, this is exptected, especially when using quanization, see discussion [here](https://discuss.huggingface.co/t/model-merging-leads-to-different-output/103986/3).\n"
      ],
      "metadata": {
        "id": "i4Na6kbZTCKS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load base model from Hugging Face Hub\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "from peft import AutoPeftModelForCausalLM, PeftModel\n",
        "\n",
        "base_model_name = \"meta-llama/Llama-3.1-8B-Instruct\" # \"meta-llama/Llama-3.2-1B-Instruct\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(base_model_name, padding_side=\"left\", use_fast=True)\n",
        "\n",
        "######\n",
        "# Use this to load the model quantized in the same fashion as during fine-tuning of Lora\n",
        "######\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
        ")\n",
        "model = AutoModelForCausalLM.from_pretrained(base_model_name, quantization_config=bnb_config).eval().to(device)\n",
        "\n",
        "######\n",
        "# Use this to use the model without quantization\n",
        "######\n",
        "#model = AutoModelForCausalLM.from_pretrained(base_model_name).eval().to(device)\n",
        "\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "87CPkpYI0hTP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Run base model\n",
        "\n",
        "Use the base mode to generate answers for the questions in the evaluation dataset, and store these answers in github.\n"
      ],
      "metadata": {
        "id": "YKxKin0VCgD3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# generate answers for base model\n",
        "dataset_with_answers = evaluate_model(model, dataset, greedy=True)\n",
        "# push dataset contaning generate answer to github\n",
        "push_results_to_git(dataset_with_answers, adapter=Adapter(name=\"Llama-3.1-8B-Instruct\", subfolder=\"base\"))"
      ],
      "metadata": {
        "id": "XFh3u4rgli0i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Run LoRA adapters\n",
        "\n",
        "Use each of the fine-tuned LoRA adapters to generate answers for the questions in the evaluation dataset, and store these answers in github.\n"
      ],
      "metadata": {
        "id": "XiQPmn2yCVHX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#evaluate first adapter\n",
        "\n",
        "namespace=\"mpenna77\"\n",
        "adapter=Adapter(name=\"Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-continuous-lora-cthulhu\", subfolder=\"checkpoint-450\")\n",
        "#adapter=Adapter(name=\"Llama-3.2-1B-Instruct-lr0.0001-b64-r16-a32-lora-cthulhu\", subfolder=\"best-model\")\n",
        "\n",
        "# load adapter model\n",
        "peft_model = PeftModel.from_pretrained(model, f\"{namespace}/{adapter.name}\", subfolder=adapter.subfolder).eval().to(device)\n",
        "## generate answers\n",
        "dataset_with_answers = evaluate_model(peft_model, dataset, greedy=True)\n",
        "# push dataset contaning generate answer to github\n",
        "push_results_to_git(dataset_with_answers, adapter=adapter)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "6jajaAobJ3KJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#evaluate all other adapters\n",
        "\n",
        "adapters = [\n",
        "    Adapter(name=\"Llama-3.1-8B-Instruct-lr0.0001-b16-r64-a32-lora-cthulhu\", subfolder=\"checkpoint-2127\"),\n",
        "    Adapter(name=\"Llama-3.1-8B-Instruct-lr0.0001-b16-r16-a32-lora-cthulhu\", subfolder=\"checkpoint-2127\"),\n",
        "    Adapter(name=\"Llama-3.1-8B-Instruct-lr0.0001-b16-r16-a32-lora-cthulhu\", subfolder=\"best-model\"),\n",
        "    Adapter(name=\"Llama-3.1-8B-Instruct-lr3e-05-b32-r16-a32-lora-cthulhu\", subfolder=\"checkpoint-1420\"),\n",
        "    Adapter(name=\"Llama-3.1-8B-Instruct-lr3e-05-b32-r16-a32-lora-cthulhu\", subfolder=\"best-model\"),\n",
        "    Adapter(name=\"Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-continuous-no_head-lora-cthulhu\", subfolder=\"checkpoint-455\"),\n",
        "    Adapter(name=\"Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-combo-no_head-lora-cthulhu\", subfolder=\"checkpoint-518\"),\n",
        "]\n",
        "for adapter in adapters:\n",
        "  print(f\"Generating for adapter: {adapter.name}\")\n",
        "  # load adapter\n",
        "  peft_model.load_adapter(f\"{namespace}/{adapter.name}\", subfolder=adapter.subfolder, adapter_name=adapter.shortname)\n",
        "  # set adapter\n",
        "  peft_model.set_adapter(adapter.shortname)\n",
        "  # generate answers\n",
        "  dataset_with_answers = evaluate_model(peft_model, dataset, greedy=True)\n",
        "  # push dataset contaning generate answer to github\n",
        "  push_results_to_git(dataset_with_answers, adapter)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ZXSW5nErd8KG",
        "outputId": "74ae438f-e35c-46b6-ecaf-7f5ec82650ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nfor adapter in adapters:\\n  print(f\"Generating for adapter: {adapter.name}\")\\n  # load adapter\\n  peft_model.load_adapter(f\"{namespace}/{adapter.name}\", subfolder=adapter.subfolder, adapter_name=adapter.shortname)\\n  # set adapter\\n  peft_model.set_adapter(adapter.shortname)\\n  # generate answers\\n  dataset_with_answers = evaluate_model_on_dataset(peft_model, dataset, greedy=True)\\n  # push to git\\n  push_results_to_git(dataset_with_answers, adapter)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. Run stacked LoRA adapters\n",
        "\n",
        "Use stacked LoRA adapters to generate answers for the questions in the evaluation dataset, and store these answers in github.\n",
        "\n",
        "I experimented two setups. These setups should lead to the same answers. However we double check both of them to double check that the HF libraries are working as expected.\n",
        "\n",
        "1. **Base + qa + continuted** \\\\\n",
        "First merge the QA Adapter (i.e. the adapter tuned with the QA dataset) to the base mode, and then add the Continued Adapter (i.e. the adapter trained with the Continued Pretrained dataset) on top.\n",
        "\n",
        "2. **Base + continuted + qa** \\\\\n",
        "First merge the Continued Adapter to the base mode, and then add the QA Adapter on top.\n",
        "\n",
        "I also tried to use `add_weighted_adapter()` function (see [here](https://huggingface.co/docs/peft/main/en/developer_guides/lora#merge-lora-weights-into-the-base-model)) in order to stack two adapters, but this approach leads to generate gibberish text. This should be investigated further.\n",
        "\n",
        "**Important:** Before running the code below, reload the base model from scratch.\n",
        ""
      ],
      "metadata": {
        "id": "rYsLfyUEGN0Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#########################\n",
        "# Base + qa + cotinuted #\n",
        "#########################\n",
        "\n",
        "# TODO: https://kaitchup.substack.com/p/lora-adapters-when-a-naive-merge\n",
        "\n",
        "namespace=\"mpenna77\"\n",
        "\n",
        "\n",
        "# load QA adapter\n",
        "qa_adapter = Adapter(name=\"Llama-3.1-8B-Instruct-lr0.0001-b16-r64-a32-lora-cthulhu\", subfolder=\"checkpoint-2127\")\n",
        "peft_model = PeftModel.from_pretrained(model, f\"{namespace}/{qa_adapter.name}\", subfolder=qa_adapter.subfolder, adapter_name=\"qa\").eval().to(device)\n",
        "# set QA adapter\n",
        "peft_model.set_adapter(\"qa\")\n",
        "print(f\"current active adapters: {peft_model.active_adapters}\")\n",
        "# merge QA adapter\n",
        "peft_model.merge_and_unload()\n",
        "\n",
        "\n",
        "# load cont adapter\n",
        "#   we need to use a new name for the adapter, otherwise it seems like the adapter\n",
        "#   has not effect (probably it gets unloaded after the merge_and_unload())\n",
        "cont_adapter = Adapter(name=\"Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-continuous-no_head-lora-cthulhu\", subfolder=\"checkpoint-455\")\n",
        "peft_model.load_adapter(f\"{namespace}/{cont_adapter.name}\", subfolder=cont_adapter.subfolder, adapter_name=\"cont\")\n",
        "# set cont adapter\n",
        "peft_model.set_adapter(\"cont\")\n",
        "print(f\"current active adapters: {peft_model.active_adapters}\")\n",
        "\n",
        "\n",
        "# generate answers\n",
        "dataset_with_answers = evaluate_model(peft_model, dataset, greedy=True)\n",
        "# push to git\n",
        "push_results_to_git(dataset_with_answers, Adapter(name=\"Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-merged_qa-adapter_cont-lora-cthulhu\", subfolder=\"checkpoint-last\"))"
      ],
      "metadata": {
        "id": "JTeHRJm_GQGh",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#########################\n",
        "# Base + cotinuted + qa #\n",
        "#########################\n",
        "\n",
        "namespace=\"mpenna77\"\n",
        "\n",
        "# load cont adapter\n",
        "cont_adapter = Adapter(name=\"Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-continuous-no_head-lora-cthulhu\", subfolder=\"checkpoint-455\")\n",
        "peft_model = PeftModel.from_pretrained(model, f\"{namespace}/{cont_adapter.name}\", subfolder=cont_adapter.subfolder, adapter_name=\"cont\").eval().to(device)\n",
        "# set cont adapter\n",
        "peft_model.set_adapter(\"cont\")\n",
        "print(f\"current active adapters: {peft_model.active_adapters}\")\n",
        "# merge cont adapter\n",
        "peft_model.merge_and_unload()\n",
        "\n",
        "#load qa adapter\n",
        "qa_adapter = Adapter(name=\"Llama-3.1-8B-Instruct-lr0.0001-b16-r64-a32-lora-cthulhu\", subfolder=\"checkpoint-2127\")\n",
        "peft_model.load_adapter(f\"{namespace}/{qa_adapter.name}\", subfolder=qa_adapter.subfolder, adapter_name=\"qa\")\n",
        "# set qa adapter\n",
        "peft_model.set_adapter(\"qa\")\n",
        "print(f\"current active adapters: {peft_model.active_adapters}\")\n",
        "\n",
        "\n",
        "# generate answers\n",
        "dataset_with_answers = evaluate_model(peft_model, dataset, greedy=True)\n",
        "# push to git\n",
        "push_results_to_git(dataset_with_answers, Adapter(name=\"Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-merged_cont-adapter_qa-lora-cthulhu\", subfolder=\"checkpoint-last\"))"
      ],
      "metadata": {
        "collapsed": true,
        "id": "VkF2RcDxbP-F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8. Run RAG agent\n",
        "\n",
        "Use a simple RAG agent to generate answers for the questions in the evaluation dataset, and store these answers in github.\n",
        "\n",
        "I used [Langchain](https://www.langchain.com/) to implement the RAG agent. The vector database supporting the agent is created as follows:\n",
        "- Split the Cthulhu Rule Book into chunks of 1000 characters, overlapping of 100 characters.\n",
        "- Generate an embedding for each chunk using the [jinaai/jina-embeddings-v3](https://huggingface.co/jinaai/jina-embeddings-v3) embedding model. This model is known to perform well on RAG tasks.\n",
        "- Store the embeddings in a [FAISS](https://python.langchain.com/docs/integrations/vectorstores/faiss/) in-memory vector database\n",
        "\n",
        "At inference time, the system answers each question from the evaluation dataset using the following typical RAG approach:\n",
        "- the question is projected in the embedding space, and the top-5 most similar chunks from the vector database are retrieved\n",
        "- The `Llama-3.1-8B-Instruct` language model is invoked to generate the answer. The model is provided a typical RAG context as input, including:\n",
        "  1. a system prompt that recommends the model to base the answer on the top-5 chunks;\n",
        "  2. a user prompt that contains the text of the top-5 chunks\n",
        "\n"
      ],
      "metadata": {
        "id": "S3n8WDGP8eI2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Split Rulebook into chunks\n",
        "\n",
        "from langchain_community.document_loaders.text import TextLoader\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "\n",
        "%cd /content/cthulhu_fine_tuning\n",
        "\n",
        "\n",
        "# load cthulhu document file\n",
        "loader = TextLoader(\"data/output/cthulhu.txt\", encoding=\"utf-8\")\n",
        "doc = loader.load()\n",
        "\n",
        "# spit document into chunks\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1000,\n",
        "    chunk_overlap=100,\n",
        "    length_function=len,\n",
        "    strip_whitespace=True,\n",
        "    add_start_index=True,\n",
        "    separators = [\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
        ")\n",
        "\n",
        "chunks = text_splitter.split_documents(doc)\n",
        "\n",
        "print(f\"Number of generated chunks: {len(chunks)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zyeV4WGv8lbm",
        "outputId": "c97ffc48-0b7d-4dbd-ada4-6ae4d98f29e6"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/cthulhu_fine_tuning\n",
            "Number of generated chunks: 2167\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Load embedding model\n",
        "\n",
        "import torch\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "\n",
        "EMBEDDING_MODEL_NAME = \"jinaai/jina-embeddings-v3\"\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "\n",
        "embedding_model = HuggingFaceEmbeddings(\n",
        "    model_name=EMBEDDING_MODEL_NAME,\n",
        "    model_kwargs={\"device\": device, \"trust_remote_code\":True},\n",
        "    encode_kwargs={\"normalize_embeddings\": True, \"convert_to_numpy\":True},  # Set `True` for cosine similarity\n",
        "    show_progress=True,\n",
        ")"
      ],
      "metadata": {
        "id": "wCYxvXVF-Z_h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate embeddings for chunks and populate Faiss vector database\n",
        "\n",
        "import faiss\n",
        "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
        "from langchain_community.vectorstores import FAISS\n",
        "\n",
        "faiss_store = FAISS(\n",
        "    embedding_function=embedding_model,\n",
        "    index=faiss.IndexFlatL2(len(embedding_model.embed_query(\"hello world\"))),\n",
        "    docstore=InMemoryDocstore(),\n",
        "    index_to_docstore_id={},\n",
        ")\n",
        "\n",
        "faiss_store.add_documents(chunks)"
      ],
      "metadata": {
        "id": "U-IqEVRg-vNl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate RAG with base model\n",
        "\n",
        "dataset_with_answers = evaluate_model_rag(peft_model, dataset, faiss_store, greedy=True)\n",
        "push_results_to_git(dataset_with_answers, Adapter(name=\"Llama-3.1-8B-Instruct-RAG\", subfolder=\"base\"))"
      ],
      "metadata": {
        "id": "ZFAdOWzL-8gq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 9. Run RAG agent with stacked LoRA adapters\n",
        "\n",
        "Use a simple RAG agent with stacked adapters to generate answers for the questions in the evaluation dataset, and store these answers in github.\n",
        "\n",
        "This is the same as in (8). However instead of using `Llama-3.1-8B-Instruct` as language model, we use `Llama-3.1-8B-Instruct` with stacked Lora adapters as in (7), i.e. _base + qa + continuted_."
      ],
      "metadata": {
        "id": "DDiI988DBvLd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate RAG with PEFT adapters\n",
        "\n",
        "namespace=\"mpenna77\"\n",
        "qa_adapter = Adapter(name=\"Llama-3.1-8B-Instruct-lr0.0001-b16-r64-a32-lora-cthulhu\", subfolder=\"checkpoint-2127\")\n",
        "peft_model = PeftModel.from_pretrained(model, f\"{namespace}/{qa_adapter.name}\", subfolder=qa_adapter.subfolder, adapter_name=\"qa\").eval().to(device)\n",
        "peft_model.set_adapter(\"qa\")\n",
        "peft_model.merge_and_unload()\n",
        "\n",
        "cont_adapter = Adapter(name=\"Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-continuous-no_head-lora-cthulhu\", subfolder=\"checkpoint-455\")\n",
        "peft_model.load_adapter(f\"{namespace}/{cont_adapter.name}\", subfolder=cont_adapter.subfolder, adapter_name=\"cont\")\n",
        "peft_model.set_adapter(\"cont\")\n",
        "\n",
        "dataset_with_answers = evaluate_model_rag(peft_model, dataset, faiss_store, greedy=True)\n",
        "\n",
        "push_results_to_git(\n",
        "    dataset_with_answers,\n",
        "    Adapter(name=\"Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-merged_qa-adapter_cont-lora-cthulhu-RAG\", subfolder=\"checkpoint-last\"),\n",
        "    quantized_model=True\n",
        ")"
      ],
      "metadata": {
        "id": "jUnRarEJJEjm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# show results\n",
        "\n",
        "import pandas as pd\n",
        "df = pd.DataFrame(\n",
        "    {\n",
        "        \"question\": dataset_with_answers[\"question\"],\n",
        "        \"answer\": dataset_with_answers[\"answer\"],\n",
        "        \"generated_answer\": dataset_with_answers[\"generated_answer\"],\n",
        "        \"rag_top_docs\": dataset_with_answers[\"rag_top_docs\"]\n",
        "    }\n",
        ")\n",
        "\n",
        "df"
      ],
      "metadata": {
        "id": "AXLEmRMOAC63"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 10. Prepare manual annotation file\n",
        "\n",
        "This is code that generates a CSV file, which contains the original 50 questions from the evaluation dataset, and, for each question, the answers generated by all systems experimented in this notebook.\n",
        "\n",
        "This CSV file is used to perform a manual evaluation of the experiment systems. Each answer generated by a system, is evaluate on three metrics: **fluency**, **topicality** and **correctness**. Each answer is scored on each metric with values from 1 (worse) to 5 (best). See README.md for details on the manual annotation process."
      ],
      "metadata": {
        "id": "fNF1yFOsLWDf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "import csv\n",
        "from pathlib import Path\n",
        "\n",
        "%cd /content/cthulhu_fine_tuning\n",
        "\n",
        "# set evaluation metrics\n",
        "metrics = [\"Fluency\", \"Topicality\", \"Correctness\"]\n",
        "system_names = []\n",
        "answers = {}\n",
        "\n",
        "# load generated answer from all systems\n",
        "for file_name in glob.glob(\"evaluation/evaluation-results*/*csv\"):\n",
        "  system_name = Path(file_name).stem.replace(\"res_\",\"\")\n",
        "  if \"quantized\" in file_name:\n",
        "    system_name = system_name + \"-quantized\"\n",
        "  system_names.append(system_name)\n",
        "  with open(file_name, \"r\") as f:\n",
        "    reader = csv.DictReader(f)\n",
        "    answers[system_name] = [row[\"generated_answer\"] for row in reader]\n",
        "\n",
        "# load ground truth questions and answers\n",
        "questions = []\n",
        "gs_answers = []\n",
        "with open(glob.glob(\"evaluation/evaluation-results*/*csv\")[0], \"r\") as f:\n",
        "    reader = csv.DictReader(f)\n",
        "    for row in reader:\n",
        "      questions.append(row[\"question\"])\n",
        "      gs_answers.append(row[\"answer\"])\n",
        "\n",
        "# write annotation file\n",
        "header = []\n",
        "header.append(\"question\")\n",
        "header.append(\"ground_truth_answer\")\n",
        "for system_name in system_names:\n",
        "  header.append(f\"{system_name} - generated_answer\")\n",
        "  for metric in metrics:\n",
        "    header.append(f\"{system_name} - {metric}\")\n",
        "\n",
        "Path(\"evaluation/manual-annotation/\").mkdir(exist_ok=True)\n",
        "\n",
        "with open(\"evaluation/manual-annotation/manual_annotation.csv\", \"w\") as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "    writer.writerow(header)\n",
        "    for i in range(len(gs_answers)):\n",
        "      row = [questions[i]]\n",
        "      row.append(gs_answers[i])\n",
        "      for system_name in system_names:\n",
        "        row.append(answers[system_name][i])\n",
        "        for metric in metrics:\n",
        "          row.append(\"\")\n",
        "      writer.writerow(row)\n",
        "\n",
        "# push annotation file to git\n",
        "! git config --global user.email \"marco.pennacchiotti@gmail.com\"\n",
        "! git add evaluation/manual-annotation/manual_annotation.csv\n",
        "! git commit -m \"added manual annotation\"\n",
        "! git push origin main\n"
      ],
      "metadata": {
        "id": "SXRe_ez4LVqr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 11. Evaluate systems\n",
        "\n",
        "Code to read the results of the manual annotation, compute the performance of each system, and create plots for these.\n",
        "\n",
        "For each of the performance metrics (**fluency**, **topicality**, **correctness**) I compute the average across the dataset, together with the 0.05 and 0.95 percentile."
      ],
      "metadata": {
        "id": "lqc5kr4cHMN5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load data"
      ],
      "metadata": {
        "id": "W6GM2drJpjkE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Loaded annotated file including annotation for each system\n",
        "\n",
        "import csv\n",
        "import pandas as pd\n",
        "\n",
        "%cd /content/cthulhu_fine_tuning\n",
        "\n",
        "with open(\"evaluation/manual-annotation/manual_annotation_completed.csv\") as f:\n",
        "  df = pd.read_csv(f)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gB7eug8uHayM",
        "outputId": "cccc1138-b6c2-40cd-caaa-6fcbf3857cbb"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/cthulhu_fine_tuning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check that all manual rating are in set {1,2,3,4,5}\n",
        "# by computing numbers of cell that are not in the set\n",
        "\n",
        "print(\"number of cells with annotations out of range:\")\n",
        "print(f\"Fluency: {(~df.filter(regex='Fluency')).isin([1,2,3,4,5]).sum().sum()}\")\n",
        "print(f\"Topicality: {(~df.filter(regex='Topicality')).isin([1,2,3,4,5]).sum().sum()}\")\n",
        "print(f\"Correctness: {(~df.filter(regex='Correctness')).isin([1,2,3,4,5]).sum().sum()}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CRP1dlZDM3X9",
        "outputId": "a22965f8-75ad-4c8f-f6bc-445db216a477"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number of cells with annotations out of range:\n",
            "Fluency: 0\n",
            "Topicality: 0\n",
            "Correctness: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Brakedown by metrics"
      ],
      "metadata": {
        "id": "Psem-fenpmry"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For each system, compute the average Correctness across the dataset, together\n",
        "# with 0.05 and 0.95 quantiles\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def quantile_05(arr):\n",
        "  return arr.quantile(q=0.5)\n",
        "\n",
        "def quantile_95(arr):\n",
        "  return arr.quantile(q=0.95)\n",
        "\n",
        "df_cor = df.filter(regex=\"Correctness\")\n",
        "(df_cor.agg([\"mean\", quantile_05, quantile_95], axis=0).transpose()).sort_values(by=\"mean\", ascending=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 865
        },
        "id": "rWVmAHJ01h_3",
        "outputId": "ec5d05db-a998-42fe-af0c-b9cbde15e610",
        "collapsed": true
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                    mean  quantile_05  \\\n",
              "Llama-3.1-8B-Instruct-RAG-base-quantized - Corr...  4.04          5.0   \n",
              "Llama-3.1-8B-Instruct-RAG-base - Correctness        4.00          5.0   \n",
              "Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-cont...  3.00          3.0   \n",
              "Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-merg...  2.60          2.0   \n",
              "Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-cont...  2.48          2.0   \n",
              "Llama-3.1-8B-Instruct-lr3e-05-b32-r16-a32-lora-...  2.36          2.0   \n",
              "Llama-3.1-8B-Instruct-lr0.0001-b16-r16-a32-lora...  2.34          2.0   \n",
              "Llama-3.1-8B-Instruct-lr3e-05-b32-r16-a32-lora-...  2.34          2.0   \n",
              "Llama-3.1-8B-Instruct-lr0.0001-b16-r16-a32-lora...  2.32          2.0   \n",
              "Llama-3.1-8B-Instruct-lr0.0001-b16-r64-a32-lora...  2.32          2.0   \n",
              "Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-cont...  2.30          2.0   \n",
              "Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-cont...  2.28          1.0   \n",
              "Llama-3.1-8B-Instruct-lr0.0001-b16-r16-a32-lora...  2.22          2.0   \n",
              "Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-cont...  2.22          1.0   \n",
              "Llama-3.1-8B-Instruct-lr3e-05-b32-r16-a32-lora-...  2.20          2.0   \n",
              "Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-comb...  2.20          1.0   \n",
              "Llama-3.1-8B-Instruct-lr3e-05-b32-r16-a32-lora-...  2.16          1.5   \n",
              "Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-comb...  2.14          1.0   \n",
              "Llama-3.1-8B-Instruct-lr0.0001-b16-r16-a32-lora...  2.12          2.0   \n",
              "Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-merg...  2.00          1.5   \n",
              "Llama-3.1-8B-Instruct-lr0.0001-b16-r64-a32-lora...  1.98          1.0   \n",
              "Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-merg...  1.98          1.0   \n",
              "Llama-3.2-1B-Instruct-lr0.0001-b64-r16-a32-lora...  1.74          1.0   \n",
              "Llama-3.1-8B-Instruct-base-quantized - Correctness  1.48          1.0   \n",
              "Llama-3.1-8B-Instruct-base - Correctness            1.44          1.0   \n",
              "Llama-3.2-1B-Instruct-base - Correctness            1.40          1.0   \n",
              "\n",
              "                                                    quantile_95  \n",
              "Llama-3.1-8B-Instruct-RAG-base-quantized - Corr...         5.00  \n",
              "Llama-3.1-8B-Instruct-RAG-base - Correctness               5.00  \n",
              "Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-cont...         5.00  \n",
              "Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-merg...         5.00  \n",
              "Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-cont...         5.00  \n",
              "Llama-3.1-8B-Instruct-lr3e-05-b32-r16-a32-lora-...         5.00  \n",
              "Llama-3.1-8B-Instruct-lr0.0001-b16-r16-a32-lora...         5.00  \n",
              "Llama-3.1-8B-Instruct-lr3e-05-b32-r16-a32-lora-...         5.00  \n",
              "Llama-3.1-8B-Instruct-lr0.0001-b16-r16-a32-lora...         5.00  \n",
              "Llama-3.1-8B-Instruct-lr0.0001-b16-r64-a32-lora...         5.00  \n",
              "Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-cont...         5.00  \n",
              "Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-cont...         5.00  \n",
              "Llama-3.1-8B-Instruct-lr0.0001-b16-r16-a32-lora...         5.00  \n",
              "Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-cont...         5.00  \n",
              "Llama-3.1-8B-Instruct-lr3e-05-b32-r16-a32-lora-...         5.00  \n",
              "Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-comb...         5.00  \n",
              "Llama-3.1-8B-Instruct-lr3e-05-b32-r16-a32-lora-...         5.00  \n",
              "Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-comb...         5.00  \n",
              "Llama-3.1-8B-Instruct-lr0.0001-b16-r16-a32-lora...         5.00  \n",
              "Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-merg...         5.00  \n",
              "Llama-3.1-8B-Instruct-lr0.0001-b16-r64-a32-lora...         5.00  \n",
              "Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-merg...         5.00  \n",
              "Llama-3.2-1B-Instruct-lr0.0001-b64-r16-a32-lora...         4.00  \n",
              "Llama-3.1-8B-Instruct-base-quantized - Correctness         4.55  \n",
              "Llama-3.1-8B-Instruct-base - Correctness                   3.55  \n",
              "Llama-3.2-1B-Instruct-base - Correctness                   4.00  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0d766443-9bbf-4fc6-9ca1-af63ae9c64dc\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean</th>\n",
              "      <th>quantile_05</th>\n",
              "      <th>quantile_95</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Llama-3.1-8B-Instruct-RAG-base-quantized - Correctness</th>\n",
              "      <td>4.04</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Llama-3.1-8B-Instruct-RAG-base - Correctness</th>\n",
              "      <td>4.00</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-continuous-lora-cthulhu-RAG-checkpoint-450 - Correctness</th>\n",
              "      <td>3.00</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-merged_qa-adapter_cont-lora-cthulhu-RAG-checkpoint-last-quantized - Correctness</th>\n",
              "      <td>2.60</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-continuous-no_head-lora-cthulhu-checkpoint-455 - Correctness</th>\n",
              "      <td>2.48</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Llama-3.1-8B-Instruct-lr3e-05-b32-r16-a32-lora-cthulhu-best-model-quantized - Correctness</th>\n",
              "      <td>2.36</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Llama-3.1-8B-Instruct-lr0.0001-b16-r16-a32-lora-cthulhu-best-model - Correctness</th>\n",
              "      <td>2.34</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Llama-3.1-8B-Instruct-lr3e-05-b32-r16-a32-lora-cthulhu-best-model - Correctness</th>\n",
              "      <td>2.34</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Llama-3.1-8B-Instruct-lr0.0001-b16-r16-a32-lora-cthulhu-checkpoint-2127 - Correctness</th>\n",
              "      <td>2.32</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Llama-3.1-8B-Instruct-lr0.0001-b16-r64-a32-lora-cthulhu-checkpoint-2127 - Correctness</th>\n",
              "      <td>2.32</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-continuous-no_head-lora-cthulhu-checkpoint-455-quantized - Correctness</th>\n",
              "      <td>2.30</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-continuous-lora-cthulhu-checkpoint-450-quantized - Correctness</th>\n",
              "      <td>2.28</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Llama-3.1-8B-Instruct-lr0.0001-b16-r16-a32-lora-cthulhu-best-model-quantized - Correctness</th>\n",
              "      <td>2.22</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-continuous-lora-cthulhu-checkpoint-450 - Correctness</th>\n",
              "      <td>2.22</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Llama-3.1-8B-Instruct-lr3e-05-b32-r16-a32-lora-cthulhu-checkpoint-1420 - Correctness</th>\n",
              "      <td>2.20</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-combo-no_head-lora-cthulhu-checkpoint-518 - Correctness</th>\n",
              "      <td>2.20</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Llama-3.1-8B-Instruct-lr3e-05-b32-r16-a32-lora-cthulhu-checkpoint-1420-quantized - Correctness</th>\n",
              "      <td>2.16</td>\n",
              "      <td>1.5</td>\n",
              "      <td>5.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-combo-no_head-lora-cthulhu-checkpoint-518-quantized - Correctness</th>\n",
              "      <td>2.14</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Llama-3.1-8B-Instruct-lr0.0001-b16-r16-a32-lora-cthulhu-checkpoint-2127-quantized - Correctness</th>\n",
              "      <td>2.12</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-merged_qa-adapter_cont-lora-cthulhu-checkpoint-last - Correctness</th>\n",
              "      <td>2.00</td>\n",
              "      <td>1.5</td>\n",
              "      <td>5.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Llama-3.1-8B-Instruct-lr0.0001-b16-r64-a32-lora-cthulhu-checkpoint-2127-quantized - Correctness</th>\n",
              "      <td>1.98</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-merged_cont-adapter_qa-lora-cthulhu-checkpoint-last - Correctness</th>\n",
              "      <td>1.98</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Llama-3.2-1B-Instruct-lr0.0001-b64-r16-a32-lora-cthulhu-best-model - Correctness</th>\n",
              "      <td>1.74</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Llama-3.1-8B-Instruct-base-quantized - Correctness</th>\n",
              "      <td>1.48</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Llama-3.1-8B-Instruct-base - Correctness</th>\n",
              "      <td>1.44</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Llama-3.2-1B-Instruct-base - Correctness</th>\n",
              "      <td>1.40</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0d766443-9bbf-4fc6-9ca1-af63ae9c64dc')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-0d766443-9bbf-4fc6-9ca1-af63ae9c64dc button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-0d766443-9bbf-4fc6-9ca1-af63ae9c64dc');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-40ab2ec8-5660-4c17-b54d-225090781ed3\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-40ab2ec8-5660-4c17-b54d-225090781ed3')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-40ab2ec8-5660-4c17-b54d-225090781ed3 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"(df_cor\",\n  \"rows\": 26,\n  \"fields\": [\n    {\n      \"column\": \"mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.615728711490577,\n        \"min\": 1.4,\n        \"max\": 4.04,\n        \"num_unique_values\": 21,\n        \"samples\": [\n          4.04,\n          1.74,\n          2.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"quantile_05\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.074888187387235,\n        \"min\": 1.0,\n        \"max\": 5.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          3.0,\n          1.5,\n          2.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"quantile_95\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.38574603043971867,\n        \"min\": 3.549999999999997,\n        \"max\": 5.0,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          4.0,\n          3.549999999999997,\n          5.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# For each system, compute the average Topicality across the dataset, together\n",
        "# with 0.05 and 0.95 quantiles\n",
        "\n",
        "df_top = df.filter(regex=\"Topicality\")\n",
        "(df_top.agg([\"mean\", quantile_05, quantile_95], axis=0).transpose()).sort_values(by=\"mean\", ascending=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 865
        },
        "id": "Lhi3jqM39-Zg",
        "outputId": "f22888f9-ea8e-4bfb-ab57-c4bef6aa861e",
        "collapsed": true
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                    mean  quantile_05  \\\n",
              "Llama-3.1-8B-Instruct-lr3e-05-b32-r16-a32-lora-...  4.94          5.0   \n",
              "Llama-3.1-8B-Instruct-lr3e-05-b32-r16-a32-lora-...  4.94          5.0   \n",
              "Llama-3.1-8B-Instruct-RAG-base - Topicality         4.92          5.0   \n",
              "Llama-3.1-8B-Instruct-lr0.0001-b16-r16-a32-lora...  4.90          5.0   \n",
              "Llama-3.1-8B-Instruct-lr0.0001-b16-r64-a32-lora...  4.90          5.0   \n",
              "Llama-3.1-8B-Instruct-lr0.0001-b16-r16-a32-lora...  4.90          5.0   \n",
              "Llama-3.1-8B-Instruct-RAG-base-quantized - Topi...  4.90          5.0   \n",
              "Llama-3.1-8B-Instruct-lr0.0001-b16-r16-a32-lora...  4.88          5.0   \n",
              "Llama-3.1-8B-Instruct-lr0.0001-b16-r64-a32-lora...  4.88          5.0   \n",
              "Llama-3.1-8B-Instruct-lr0.0001-b16-r16-a32-lora...  4.86          5.0   \n",
              "Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-comb...  4.84          5.0   \n",
              "Llama-3.1-8B-Instruct-lr3e-05-b32-r16-a32-lora-...  4.82          5.0   \n",
              "Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-merg...  4.78          5.0   \n",
              "Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-merg...  4.78          5.0   \n",
              "Llama-3.1-8B-Instruct-lr3e-05-b32-r16-a32-lora-...  4.76          5.0   \n",
              "Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-comb...  4.76          5.0   \n",
              "Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-merg...  4.74          5.0   \n",
              "Llama-3.2-1B-Instruct-lr0.0001-b64-r16-a32-lora...  4.74          5.0   \n",
              "Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-cont...  4.72          5.0   \n",
              "Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-cont...  4.48          5.0   \n",
              "Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-cont...  4.36          5.0   \n",
              "Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-cont...  4.34          5.0   \n",
              "Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-cont...  3.82          4.5   \n",
              "Llama-3.1-8B-Instruct-base-quantized - Topicality   2.46          2.0   \n",
              "Llama-3.1-8B-Instruct-base - Topicality             2.14          1.0   \n",
              "Llama-3.2-1B-Instruct-base - Topicality             2.02          1.0   \n",
              "\n",
              "                                                    quantile_95  \n",
              "Llama-3.1-8B-Instruct-lr3e-05-b32-r16-a32-lora-...          5.0  \n",
              "Llama-3.1-8B-Instruct-lr3e-05-b32-r16-a32-lora-...          5.0  \n",
              "Llama-3.1-8B-Instruct-RAG-base - Topicality                 5.0  \n",
              "Llama-3.1-8B-Instruct-lr0.0001-b16-r16-a32-lora...          5.0  \n",
              "Llama-3.1-8B-Instruct-lr0.0001-b16-r64-a32-lora...          5.0  \n",
              "Llama-3.1-8B-Instruct-lr0.0001-b16-r16-a32-lora...          5.0  \n",
              "Llama-3.1-8B-Instruct-RAG-base-quantized - Topi...          5.0  \n",
              "Llama-3.1-8B-Instruct-lr0.0001-b16-r16-a32-lora...          5.0  \n",
              "Llama-3.1-8B-Instruct-lr0.0001-b16-r64-a32-lora...          5.0  \n",
              "Llama-3.1-8B-Instruct-lr0.0001-b16-r16-a32-lora...          5.0  \n",
              "Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-comb...          5.0  \n",
              "Llama-3.1-8B-Instruct-lr3e-05-b32-r16-a32-lora-...          5.0  \n",
              "Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-merg...          5.0  \n",
              "Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-merg...          5.0  \n",
              "Llama-3.1-8B-Instruct-lr3e-05-b32-r16-a32-lora-...          5.0  \n",
              "Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-comb...          5.0  \n",
              "Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-merg...          5.0  \n",
              "Llama-3.2-1B-Instruct-lr0.0001-b64-r16-a32-lora...          5.0  \n",
              "Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-cont...          5.0  \n",
              "Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-cont...          5.0  \n",
              "Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-cont...          5.0  \n",
              "Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-cont...          5.0  \n",
              "Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-cont...          5.0  \n",
              "Llama-3.1-8B-Instruct-base-quantized - Topicality           5.0  \n",
              "Llama-3.1-8B-Instruct-base - Topicality                     5.0  \n",
              "Llama-3.2-1B-Instruct-base - Topicality                     5.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f65426d1-22b0-4f56-9661-d67aa62e07f8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean</th>\n",
              "      <th>quantile_05</th>\n",
              "      <th>quantile_95</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Llama-3.1-8B-Instruct-lr3e-05-b32-r16-a32-lora-cthulhu-checkpoint-1420-quantized - Topicality</th>\n",
              "      <td>4.94</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Llama-3.1-8B-Instruct-lr3e-05-b32-r16-a32-lora-cthulhu-best-model-quantized - Topicality</th>\n",
              "      <td>4.94</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Llama-3.1-8B-Instruct-RAG-base - Topicality</th>\n",
              "      <td>4.92</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Llama-3.1-8B-Instruct-lr0.0001-b16-r16-a32-lora-cthulhu-checkpoint-2127 - Topicality</th>\n",
              "      <td>4.90</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Llama-3.1-8B-Instruct-lr0.0001-b16-r64-a32-lora-cthulhu-checkpoint-2127 - Topicality</th>\n",
              "      <td>4.90</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Llama-3.1-8B-Instruct-lr0.0001-b16-r16-a32-lora-cthulhu-best-model - Topicality</th>\n",
              "      <td>4.90</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Llama-3.1-8B-Instruct-RAG-base-quantized - Topicality</th>\n",
              "      <td>4.90</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Llama-3.1-8B-Instruct-lr0.0001-b16-r16-a32-lora-cthulhu-best-model-quantized - Topicality</th>\n",
              "      <td>4.88</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Llama-3.1-8B-Instruct-lr0.0001-b16-r64-a32-lora-cthulhu-checkpoint-2127-quantized - Topicality</th>\n",
              "      <td>4.88</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Llama-3.1-8B-Instruct-lr0.0001-b16-r16-a32-lora-cthulhu-checkpoint-2127-quantized - Topicality</th>\n",
              "      <td>4.86</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-combo-no_head-lora-cthulhu-checkpoint-518 - Topicality</th>\n",
              "      <td>4.84</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Llama-3.1-8B-Instruct-lr3e-05-b32-r16-a32-lora-cthulhu-checkpoint-1420 - Topicality</th>\n",
              "      <td>4.82</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-merged_cont-adapter_qa-lora-cthulhu-checkpoint-last - Topicality</th>\n",
              "      <td>4.78</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-merged_qa-adapter_cont-lora-cthulhu-checkpoint-last - Topicality</th>\n",
              "      <td>4.78</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Llama-3.1-8B-Instruct-lr3e-05-b32-r16-a32-lora-cthulhu-best-model - Topicality</th>\n",
              "      <td>4.76</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-combo-no_head-lora-cthulhu-checkpoint-518-quantized - Topicality</th>\n",
              "      <td>4.76</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-merged_qa-adapter_cont-lora-cthulhu-RAG-checkpoint-last-quantized - Topicality</th>\n",
              "      <td>4.74</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Llama-3.2-1B-Instruct-lr0.0001-b64-r16-a32-lora-cthulhu-best-model - Topicality</th>\n",
              "      <td>4.74</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-continuous-lora-cthulhu-RAG-checkpoint-450 - Topicality</th>\n",
              "      <td>4.72</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-continuous-no_head-lora-cthulhu-checkpoint-455-quantized - Topicality</th>\n",
              "      <td>4.48</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-continuous-lora-cthulhu-checkpoint-450-quantized - Topicality</th>\n",
              "      <td>4.36</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-continuous-no_head-lora-cthulhu-checkpoint-455 - Topicality</th>\n",
              "      <td>4.34</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-continuous-lora-cthulhu-checkpoint-450 - Topicality</th>\n",
              "      <td>3.82</td>\n",
              "      <td>4.5</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Llama-3.1-8B-Instruct-base-quantized - Topicality</th>\n",
              "      <td>2.46</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Llama-3.1-8B-Instruct-base - Topicality</th>\n",
              "      <td>2.14</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Llama-3.2-1B-Instruct-base - Topicality</th>\n",
              "      <td>2.02</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f65426d1-22b0-4f56-9661-d67aa62e07f8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f65426d1-22b0-4f56-9661-d67aa62e07f8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f65426d1-22b0-4f56-9661-d67aa62e07f8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-5aa82c62-d749-4d21-aa59-bad10d381d53\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-5aa82c62-d749-4d21-aa59-bad10d381d53')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-5aa82c62-d749-4d21-aa59-bad10d381d53 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"(df_top\",\n  \"rows\": 26,\n  \"fields\": [\n    {\n      \"column\": \"mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.862731618844381,\n        \"min\": 2.02,\n        \"max\": 4.94,\n        \"num_unique_values\": 18,\n        \"samples\": [\n          4.94,\n          4.92,\n          4.76\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"quantile_05\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.2027212734205965,\n        \"min\": 1.0,\n        \"max\": 5.0,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          4.5,\n          1.0,\n          5.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"quantile_95\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 5.0,\n        \"max\": 5.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          5.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For each system, compute the average Fluency across the dataset, together\n",
        "# with 0.05 and 0.95 quantiles\n",
        "\n",
        "df_flu = df.filter(regex=\"Fluency\")\n",
        "(df_flu.agg([\"mean\", quantile_05, quantile_95], axis=0).transpose()).sort_values(by=\"mean\", ascending=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 865
        },
        "id": "DAmw-BIb-I3I",
        "outputId": "08543dee-b60f-46f5-9d01-51021fdb22c2",
        "collapsed": true
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                    mean  quantile_05  \\\n",
              "Llama-3.1-8B-Instruct-lr0.0001-b16-r16-a32-lora...  4.96          5.0   \n",
              "Llama-3.1-8B-Instruct-RAG-base - Fluency            4.96          5.0   \n",
              "Llama-3.1-8B-Instruct-base-quantized - Fluency      4.96          5.0   \n",
              "Llama-3.1-8B-Instruct-RAG-base-quantized - Fluency  4.96          5.0   \n",
              "Llama-3.1-8B-Instruct-base - Fluency                4.96          5.0   \n",
              "Llama-3.1-8B-Instruct-lr0.0001-b16-r16-a32-lora...  4.86          5.0   \n",
              "Llama-3.1-8B-Instruct-lr0.0001-b16-r16-a32-lora...  4.84          5.0   \n",
              "Llama-3.2-1B-Instruct-base - Fluency                4.84          5.0   \n",
              "Llama-3.1-8B-Instruct-lr0.0001-b16-r16-a32-lora...  4.82          5.0   \n",
              "Llama-3.1-8B-Instruct-lr0.0001-b16-r64-a32-lora...  4.82          5.0   \n",
              "Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-comb...  4.80          5.0   \n",
              "Llama-3.1-8B-Instruct-lr3e-05-b32-r16-a32-lora-...  4.80          5.0   \n",
              "Llama-3.2-1B-Instruct-lr0.0001-b64-r16-a32-lora...  4.80          5.0   \n",
              "Llama-3.1-8B-Instruct-lr3e-05-b32-r16-a32-lora-...  4.80          5.0   \n",
              "Llama-3.1-8B-Instruct-lr0.0001-b16-r64-a32-lora...  4.78          5.0   \n",
              "Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-cont...  4.76          5.0   \n",
              "Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-cont...  4.74          5.0   \n",
              "Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-comb...  4.72          5.0   \n",
              "Llama-3.1-8B-Instruct-lr3e-05-b32-r16-a32-lora-...  4.72          5.0   \n",
              "Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-cont...  4.72          5.0   \n",
              "Llama-3.1-8B-Instruct-lr3e-05-b32-r16-a32-lora-...  4.72          5.0   \n",
              "Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-cont...  4.62          5.0   \n",
              "Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-merg...  4.58          5.0   \n",
              "Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-merg...  4.56          5.0   \n",
              "Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-cont...  4.54          5.0   \n",
              "Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-merg...  4.00          5.0   \n",
              "\n",
              "                                                    quantile_95  \n",
              "Llama-3.1-8B-Instruct-lr0.0001-b16-r16-a32-lora...          5.0  \n",
              "Llama-3.1-8B-Instruct-RAG-base - Fluency                    5.0  \n",
              "Llama-3.1-8B-Instruct-base-quantized - Fluency              5.0  \n",
              "Llama-3.1-8B-Instruct-RAG-base-quantized - Fluency          5.0  \n",
              "Llama-3.1-8B-Instruct-base - Fluency                        5.0  \n",
              "Llama-3.1-8B-Instruct-lr0.0001-b16-r16-a32-lora...          5.0  \n",
              "Llama-3.1-8B-Instruct-lr0.0001-b16-r16-a32-lora...          5.0  \n",
              "Llama-3.2-1B-Instruct-base - Fluency                        5.0  \n",
              "Llama-3.1-8B-Instruct-lr0.0001-b16-r16-a32-lora...          5.0  \n",
              "Llama-3.1-8B-Instruct-lr0.0001-b16-r64-a32-lora...          5.0  \n",
              "Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-comb...          5.0  \n",
              "Llama-3.1-8B-Instruct-lr3e-05-b32-r16-a32-lora-...          5.0  \n",
              "Llama-3.2-1B-Instruct-lr0.0001-b64-r16-a32-lora...          5.0  \n",
              "Llama-3.1-8B-Instruct-lr3e-05-b32-r16-a32-lora-...          5.0  \n",
              "Llama-3.1-8B-Instruct-lr0.0001-b16-r64-a32-lora...          5.0  \n",
              "Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-cont...          5.0  \n",
              "Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-cont...          5.0  \n",
              "Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-comb...          5.0  \n",
              "Llama-3.1-8B-Instruct-lr3e-05-b32-r16-a32-lora-...          5.0  \n",
              "Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-cont...          5.0  \n",
              "Llama-3.1-8B-Instruct-lr3e-05-b32-r16-a32-lora-...          5.0  \n",
              "Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-cont...          5.0  \n",
              "Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-merg...          5.0  \n",
              "Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-merg...          5.0  \n",
              "Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-cont...          5.0  \n",
              "Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-merg...          5.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-83131bc8-d76e-4dea-a569-ba997e54c0f5\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean</th>\n",
              "      <th>quantile_05</th>\n",
              "      <th>quantile_95</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Llama-3.1-8B-Instruct-lr0.0001-b16-r16-a32-lora-cthulhu-checkpoint-2127 - Fluency</th>\n",
              "      <td>4.96</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Llama-3.1-8B-Instruct-RAG-base - Fluency</th>\n",
              "      <td>4.96</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Llama-3.1-8B-Instruct-base-quantized - Fluency</th>\n",
              "      <td>4.96</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Llama-3.1-8B-Instruct-RAG-base-quantized - Fluency</th>\n",
              "      <td>4.96</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Llama-3.1-8B-Instruct-base - Fluency</th>\n",
              "      <td>4.96</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Llama-3.1-8B-Instruct-lr0.0001-b16-r16-a32-lora-cthulhu-best-model-quantized - Fluency</th>\n",
              "      <td>4.86</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Llama-3.1-8B-Instruct-lr0.0001-b16-r16-a32-lora-cthulhu-checkpoint-2127-quantized - Fluency</th>\n",
              "      <td>4.84</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Llama-3.2-1B-Instruct-base - Fluency</th>\n",
              "      <td>4.84</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Llama-3.1-8B-Instruct-lr0.0001-b16-r16-a32-lora-cthulhu-best-model - Fluency</th>\n",
              "      <td>4.82</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Llama-3.1-8B-Instruct-lr0.0001-b16-r64-a32-lora-cthulhu-checkpoint-2127 - Fluency</th>\n",
              "      <td>4.82</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-combo-no_head-lora-cthulhu-checkpoint-518-quantized - Fluency</th>\n",
              "      <td>4.80</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Llama-3.1-8B-Instruct-lr3e-05-b32-r16-a32-lora-cthulhu-checkpoint-1420 - Fluency</th>\n",
              "      <td>4.80</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Llama-3.2-1B-Instruct-lr0.0001-b64-r16-a32-lora-cthulhu-best-model - Fluency</th>\n",
              "      <td>4.80</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Llama-3.1-8B-Instruct-lr3e-05-b32-r16-a32-lora-cthulhu-best-model-quantized - Fluency</th>\n",
              "      <td>4.80</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Llama-3.1-8B-Instruct-lr0.0001-b16-r64-a32-lora-cthulhu-checkpoint-2127-quantized - Fluency</th>\n",
              "      <td>4.78</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-continuous-no_head-lora-cthulhu-checkpoint-455 - Fluency</th>\n",
              "      <td>4.76</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-continuous-lora-cthulhu-RAG-checkpoint-450 - Fluency</th>\n",
              "      <td>4.74</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-combo-no_head-lora-cthulhu-checkpoint-518 - Fluency</th>\n",
              "      <td>4.72</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Llama-3.1-8B-Instruct-lr3e-05-b32-r16-a32-lora-cthulhu-checkpoint-1420-quantized - Fluency</th>\n",
              "      <td>4.72</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-continuous-lora-cthulhu-checkpoint-450 - Fluency</th>\n",
              "      <td>4.72</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Llama-3.1-8B-Instruct-lr3e-05-b32-r16-a32-lora-cthulhu-best-model - Fluency</th>\n",
              "      <td>4.72</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-continuous-no_head-lora-cthulhu-checkpoint-455-quantized - Fluency</th>\n",
              "      <td>4.62</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-merged_cont-adapter_qa-lora-cthulhu-checkpoint-last - Fluency</th>\n",
              "      <td>4.58</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-merged_qa-adapter_cont-lora-cthulhu-checkpoint-last - Fluency</th>\n",
              "      <td>4.56</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-continuous-lora-cthulhu-checkpoint-450-quantized - Fluency</th>\n",
              "      <td>4.54</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-merged_qa-adapter_cont-lora-cthulhu-RAG-checkpoint-last-quantized - Fluency</th>\n",
              "      <td>4.00</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-83131bc8-d76e-4dea-a569-ba997e54c0f5')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-83131bc8-d76e-4dea-a569-ba997e54c0f5 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-83131bc8-d76e-4dea-a569-ba997e54c0f5');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-217ce558-0f90-43d6-ada6-294c5fa07fcd\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-217ce558-0f90-43d6-ada6-294c5fa07fcd')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-217ce558-0f90-43d6-ada6-294c5fa07fcd button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"(df_flu\",\n  \"rows\": 26,\n  \"fields\": [\n    {\n      \"column\": \"mean\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.19606592297960948,\n        \"min\": 4.0,\n        \"max\": 4.96,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          4.62,\n          4.56,\n          4.96\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"quantile_05\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 5.0,\n        \"max\": 5.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          5.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"quantile_95\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 5.0,\n        \"max\": 5.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          5.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Aggregated results"
      ],
      "metadata": {
        "id": "xRflnWg3prbQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Show all metrics together\n",
        "\n",
        "df_cor_x = df.filter(regex=\"Correctness\") \\\n",
        "             .agg([\"mean\"], axis=0) \\\n",
        "             .transpose() \\\n",
        "             .reset_index() \\\n",
        "             .rename(columns={\"mean\":\"Correctness\", \"index\":\"System\"}) \\\n",
        "             .replace(to_replace=r' - Correctness', value='', regex=True)\n",
        "\n",
        "df_top_x = df.filter(regex=\"Topicality\") \\\n",
        "             .agg([\"mean\"], axis=0) \\\n",
        "             .transpose() \\\n",
        "             .reset_index() \\\n",
        "             .rename(columns={\"mean\":\"Topicality\", \"index\":\"System\"}) \\\n",
        "             .replace(to_replace=r' - Topicality', value='', regex=True)\n",
        "\n",
        "df_flu_x = df.filter(regex=\"Fluency\") \\\n",
        "             .agg([\"mean\"], axis=0) \\\n",
        "             .transpose() \\\n",
        "             .reset_index() \\\n",
        "             .rename(columns={\"mean\":\"Fluency\", \"index\":\"System\"}) \\\n",
        "             .replace(to_replace=r' - Fluency', value='', regex=True)\n",
        "\n",
        "df_merged = df_cor_x.merge(df_top_x, left_on='System', right_on='System') \\\n",
        "                    .merge(df_flu_x, left_on='System', right_on='System') \\\n",
        "\n",
        "df_merged[\"Total\"] = df_merged[\"Correctness\"] * df_merged[\"Topicality\"] * df_merged[\"Fluency\"]\n",
        "\n",
        "df_merged.sort_values(by=\"Total\", ascending=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 865
        },
        "collapsed": true,
        "id": "QtSzWz7wbTRy",
        "outputId": "b4d2fe69-b92c-4415-8eee-38ad3331efed"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               System  Correctness  \\\n",
              "22           Llama-3.1-8B-Instruct-RAG-base-quantized         4.04   \n",
              "10                     Llama-3.1-8B-Instruct-RAG-base         4.00   \n",
              "1   Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-con...         3.00   \n",
              "9   Llama-3.1-8B-Instruct-lr0.0001-b16-r16-a32-lor...         2.32   \n",
              "16  Llama-3.1-8B-Instruct-lr3e-05-b32-r16-a32-lora...         2.36   \n",
              "8   Llama-3.1-8B-Instruct-lr0.0001-b16-r16-a32-lor...         2.34   \n",
              "0   Llama-3.1-8B-Instruct-lr0.0001-b16-r64-a32-lor...         2.32   \n",
              "20  Llama-3.1-8B-Instruct-lr0.0001-b16-r16-a32-lor...         2.22   \n",
              "2   Llama-3.1-8B-Instruct-lr3e-05-b32-r16-a32-lora...         2.34   \n",
              "14  Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-con...         2.48   \n",
              "4   Llama-3.1-8B-Instruct-lr3e-05-b32-r16-a32-lora...         2.20   \n",
              "17  Llama-3.1-8B-Instruct-lr3e-05-b32-r16-a32-lora...         2.16   \n",
              "6   Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-com...         2.20   \n",
              "21  Llama-3.1-8B-Instruct-lr0.0001-b16-r16-a32-lor...         2.12   \n",
              "18  Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-mer...         2.60   \n",
              "19  Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-com...         2.14   \n",
              "25  Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-con...         2.30   \n",
              "15  Llama-3.1-8B-Instruct-lr0.0001-b16-r64-a32-lor...         1.98   \n",
              "24  Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-con...         2.28   \n",
              "7   Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-mer...         2.00   \n",
              "5   Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-mer...         1.98   \n",
              "13  Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-con...         2.22   \n",
              "11  Llama-3.2-1B-Instruct-lr0.0001-b64-r16-a32-lor...         1.74   \n",
              "23               Llama-3.1-8B-Instruct-base-quantized         1.48   \n",
              "12                         Llama-3.1-8B-Instruct-base         1.44   \n",
              "3                          Llama-3.2-1B-Instruct-base         1.40   \n",
              "\n",
              "    Topicality  Fluency      Total  \n",
              "22        4.90     4.96  98.188160  \n",
              "10        4.92     4.96  97.612800  \n",
              "1         4.72     4.74  67.118400  \n",
              "9         4.90     4.96  56.385280  \n",
              "16        4.94     4.80  55.960320  \n",
              "8         4.90     4.82  55.266120  \n",
              "0         4.90     4.82  54.793760  \n",
              "20        4.88     4.86  52.651296  \n",
              "2         4.76     4.72  52.573248  \n",
              "14        4.34     4.76  51.232832  \n",
              "4         4.82     4.80  50.899200  \n",
              "17        4.94     4.72  50.364288  \n",
              "6         4.84     4.72  50.258560  \n",
              "21        4.86     4.84  49.867488  \n",
              "18        4.74     4.00  49.296000  \n",
              "19        4.76     4.80  48.894720  \n",
              "25        4.48     4.62  47.604480  \n",
              "15        4.88     4.78  46.186272  \n",
              "24        4.36     4.54  45.131232  \n",
              "7         4.78     4.56  43.593600  \n",
              "5         4.78     4.58  43.346952  \n",
              "13        3.82     4.72  40.027488  \n",
              "11        4.74     4.80  39.588480  \n",
              "23        2.46     4.96  18.058368  \n",
              "12        2.14     4.96  15.284736  \n",
              "3         2.02     4.84  13.687520  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b2fa9945-b9e7-49ea-87fa-e4ca11454807\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>System</th>\n",
              "      <th>Correctness</th>\n",
              "      <th>Topicality</th>\n",
              "      <th>Fluency</th>\n",
              "      <th>Total</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>Llama-3.1-8B-Instruct-RAG-base-quantized</td>\n",
              "      <td>4.04</td>\n",
              "      <td>4.90</td>\n",
              "      <td>4.96</td>\n",
              "      <td>98.188160</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Llama-3.1-8B-Instruct-RAG-base</td>\n",
              "      <td>4.00</td>\n",
              "      <td>4.92</td>\n",
              "      <td>4.96</td>\n",
              "      <td>97.612800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-con...</td>\n",
              "      <td>3.00</td>\n",
              "      <td>4.72</td>\n",
              "      <td>4.74</td>\n",
              "      <td>67.118400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Llama-3.1-8B-Instruct-lr0.0001-b16-r16-a32-lor...</td>\n",
              "      <td>2.32</td>\n",
              "      <td>4.90</td>\n",
              "      <td>4.96</td>\n",
              "      <td>56.385280</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Llama-3.1-8B-Instruct-lr3e-05-b32-r16-a32-lora...</td>\n",
              "      <td>2.36</td>\n",
              "      <td>4.94</td>\n",
              "      <td>4.80</td>\n",
              "      <td>55.960320</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Llama-3.1-8B-Instruct-lr0.0001-b16-r16-a32-lor...</td>\n",
              "      <td>2.34</td>\n",
              "      <td>4.90</td>\n",
              "      <td>4.82</td>\n",
              "      <td>55.266120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Llama-3.1-8B-Instruct-lr0.0001-b16-r64-a32-lor...</td>\n",
              "      <td>2.32</td>\n",
              "      <td>4.90</td>\n",
              "      <td>4.82</td>\n",
              "      <td>54.793760</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>Llama-3.1-8B-Instruct-lr0.0001-b16-r16-a32-lor...</td>\n",
              "      <td>2.22</td>\n",
              "      <td>4.88</td>\n",
              "      <td>4.86</td>\n",
              "      <td>52.651296</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Llama-3.1-8B-Instruct-lr3e-05-b32-r16-a32-lora...</td>\n",
              "      <td>2.34</td>\n",
              "      <td>4.76</td>\n",
              "      <td>4.72</td>\n",
              "      <td>52.573248</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-con...</td>\n",
              "      <td>2.48</td>\n",
              "      <td>4.34</td>\n",
              "      <td>4.76</td>\n",
              "      <td>51.232832</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Llama-3.1-8B-Instruct-lr3e-05-b32-r16-a32-lora...</td>\n",
              "      <td>2.20</td>\n",
              "      <td>4.82</td>\n",
              "      <td>4.80</td>\n",
              "      <td>50.899200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Llama-3.1-8B-Instruct-lr3e-05-b32-r16-a32-lora...</td>\n",
              "      <td>2.16</td>\n",
              "      <td>4.94</td>\n",
              "      <td>4.72</td>\n",
              "      <td>50.364288</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-com...</td>\n",
              "      <td>2.20</td>\n",
              "      <td>4.84</td>\n",
              "      <td>4.72</td>\n",
              "      <td>50.258560</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>Llama-3.1-8B-Instruct-lr0.0001-b16-r16-a32-lor...</td>\n",
              "      <td>2.12</td>\n",
              "      <td>4.86</td>\n",
              "      <td>4.84</td>\n",
              "      <td>49.867488</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-mer...</td>\n",
              "      <td>2.60</td>\n",
              "      <td>4.74</td>\n",
              "      <td>4.00</td>\n",
              "      <td>49.296000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-com...</td>\n",
              "      <td>2.14</td>\n",
              "      <td>4.76</td>\n",
              "      <td>4.80</td>\n",
              "      <td>48.894720</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-con...</td>\n",
              "      <td>2.30</td>\n",
              "      <td>4.48</td>\n",
              "      <td>4.62</td>\n",
              "      <td>47.604480</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Llama-3.1-8B-Instruct-lr0.0001-b16-r64-a32-lor...</td>\n",
              "      <td>1.98</td>\n",
              "      <td>4.88</td>\n",
              "      <td>4.78</td>\n",
              "      <td>46.186272</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-con...</td>\n",
              "      <td>2.28</td>\n",
              "      <td>4.36</td>\n",
              "      <td>4.54</td>\n",
              "      <td>45.131232</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-mer...</td>\n",
              "      <td>2.00</td>\n",
              "      <td>4.78</td>\n",
              "      <td>4.56</td>\n",
              "      <td>43.593600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-mer...</td>\n",
              "      <td>1.98</td>\n",
              "      <td>4.78</td>\n",
              "      <td>4.58</td>\n",
              "      <td>43.346952</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-con...</td>\n",
              "      <td>2.22</td>\n",
              "      <td>3.82</td>\n",
              "      <td>4.72</td>\n",
              "      <td>40.027488</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Llama-3.2-1B-Instruct-lr0.0001-b64-r16-a32-lor...</td>\n",
              "      <td>1.74</td>\n",
              "      <td>4.74</td>\n",
              "      <td>4.80</td>\n",
              "      <td>39.588480</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Llama-3.1-8B-Instruct-base-quantized</td>\n",
              "      <td>1.48</td>\n",
              "      <td>2.46</td>\n",
              "      <td>4.96</td>\n",
              "      <td>18.058368</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Llama-3.1-8B-Instruct-base</td>\n",
              "      <td>1.44</td>\n",
              "      <td>2.14</td>\n",
              "      <td>4.96</td>\n",
              "      <td>15.284736</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Llama-3.2-1B-Instruct-base</td>\n",
              "      <td>1.40</td>\n",
              "      <td>2.02</td>\n",
              "      <td>4.84</td>\n",
              "      <td>13.687520</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b2fa9945-b9e7-49ea-87fa-e4ca11454807')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b2fa9945-b9e7-49ea-87fa-e4ca11454807 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b2fa9945-b9e7-49ea-87fa-e4ca11454807');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-1b587c88-87dc-4dd4-ae6c-03ab1ece95c5\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1b587c88-87dc-4dd4-ae6c-03ab1ece95c5')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-1b587c88-87dc-4dd4-ae6c-03ab1ece95c5 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df_merged\",\n  \"rows\": 26,\n  \"fields\": [\n    {\n      \"column\": \"System\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 26,\n        \"samples\": [\n          \"Llama-3.1-8B-Instruct-lr3e-05-b32-r16-a32-lora-cthulhu-best-model\",\n          \"Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-continuous-no_head-lora-cthulhu-checkpoint-455-quantized\",\n          \"Llama-3.1-8B-Instruct-RAG-base-quantized\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Correctness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.615728711490577,\n        \"min\": 1.4,\n        \"max\": 4.04,\n        \"num_unique_values\": 21,\n        \"samples\": [\n          4.04,\n          1.74,\n          2.28\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Topicality\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.862731618844381,\n        \"min\": 2.02,\n        \"max\": 4.94,\n        \"num_unique_values\": 18,\n        \"samples\": [\n          4.9,\n          4.92,\n          4.84\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Fluency\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.19606592297960948,\n        \"min\": 4.0,\n        \"max\": 4.96,\n        \"num_unique_values\": 14,\n        \"samples\": [\n          4.62,\n          4.54,\n          4.96\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Total\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 18.875119136340167,\n        \"min\": 13.68752,\n        \"max\": 98.18816000000001,\n        \"num_unique_values\": 26,\n        \"samples\": [\n          52.57324799999999,\n          47.60448,\n          98.18816000000001\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# show only systems using: (1) QA lora adapter (2) non quantized\n",
        "df_merged[\n",
        "    df_merged[\"System\"].str.contains(\"a32-lora\") &\n",
        "    ~df_merged[\"System\"].str.contains(\"quantized\") &\n",
        "    df_merged[\"System\"].str.contains(\"-8B-\")].sort_values(by=\"Correctness\", ascending=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246
        },
        "collapsed": true,
        "id": "0BCM9oQYhGiN",
        "outputId": "7c46eadf-db43-4a69-a1de-eba87ba64459"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              System  Correctness  Topicality  \\\n",
              "2  Llama-3.1-8B-Instruct-lr3e-05-b32-r16-a32-lora...         2.34        4.76   \n",
              "8  Llama-3.1-8B-Instruct-lr0.0001-b16-r16-a32-lor...         2.34        4.90   \n",
              "0  Llama-3.1-8B-Instruct-lr0.0001-b16-r64-a32-lor...         2.32        4.90   \n",
              "9  Llama-3.1-8B-Instruct-lr0.0001-b16-r16-a32-lor...         2.32        4.90   \n",
              "4  Llama-3.1-8B-Instruct-lr3e-05-b32-r16-a32-lora...         2.20        4.82   \n",
              "\n",
              "   Fluency      Total  \n",
              "2     4.72  52.573248  \n",
              "8     4.82  55.266120  \n",
              "0     4.82  54.793760  \n",
              "9     4.96  56.385280  \n",
              "4     4.80  50.899200  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d66b8c11-4ac3-4485-af00-7ffd53b2cd5d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>System</th>\n",
              "      <th>Correctness</th>\n",
              "      <th>Topicality</th>\n",
              "      <th>Fluency</th>\n",
              "      <th>Total</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Llama-3.1-8B-Instruct-lr3e-05-b32-r16-a32-lora...</td>\n",
              "      <td>2.34</td>\n",
              "      <td>4.76</td>\n",
              "      <td>4.72</td>\n",
              "      <td>52.573248</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Llama-3.1-8B-Instruct-lr0.0001-b16-r16-a32-lor...</td>\n",
              "      <td>2.34</td>\n",
              "      <td>4.90</td>\n",
              "      <td>4.82</td>\n",
              "      <td>55.266120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Llama-3.1-8B-Instruct-lr0.0001-b16-r64-a32-lor...</td>\n",
              "      <td>2.32</td>\n",
              "      <td>4.90</td>\n",
              "      <td>4.82</td>\n",
              "      <td>54.793760</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Llama-3.1-8B-Instruct-lr0.0001-b16-r16-a32-lor...</td>\n",
              "      <td>2.32</td>\n",
              "      <td>4.90</td>\n",
              "      <td>4.96</td>\n",
              "      <td>56.385280</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Llama-3.1-8B-Instruct-lr3e-05-b32-r16-a32-lora...</td>\n",
              "      <td>2.20</td>\n",
              "      <td>4.82</td>\n",
              "      <td>4.80</td>\n",
              "      <td>50.899200</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d66b8c11-4ac3-4485-af00-7ffd53b2cd5d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d66b8c11-4ac3-4485-af00-7ffd53b2cd5d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d66b8c11-4ac3-4485-af00-7ffd53b2cd5d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-d594a080-5942-4799-a781-34ed5f15ed38\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d594a080-5942-4799-a781-34ed5f15ed38')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-d594a080-5942-4799-a781-34ed5f15ed38 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"    df_merged[\\\"System\\\"]\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"System\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Llama-3.1-8B-Instruct-lr0.0001-b16-r16-a32-lora-cthulhu-best-model\",\n          \"Llama-3.1-8B-Instruct-lr3e-05-b32-r16-a32-lora-cthulhu-checkpoint-1420\",\n          \"Llama-3.1-8B-Instruct-lr0.0001-b16-r64-a32-lora-cthulhu-checkpoint-2127\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Correctness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05899152481501036,\n        \"min\": 2.2,\n        \"max\": 2.34,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          2.34,\n          2.32,\n          2.2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Topicality\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.06387487769068546,\n        \"min\": 4.76,\n        \"max\": 4.9,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          4.76,\n          4.9,\n          4.82\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Fluency\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.08648699324175868,\n        \"min\": 4.72,\n        \"max\": 4.96,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          4.82,\n          4.8,\n          4.72\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Total\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.212006989792937,\n        \"min\": 50.8992,\n        \"max\": 56.38528,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          55.26612,\n          50.8992,\n          54.793760000000006\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# show only systems using: (1) continuous lora adapter (2) non quantized (3) 8B\n",
        "df_merged[\n",
        "    df_merged[\"System\"].str.contains(\"a32-continuous\") &\n",
        "    df_merged[\"System\"].str.contains(\"-8B-\") &\n",
        "    ~df_merged[\"System\"].str.contains(\"RAG\")].sort_values(by=\"Correctness\", ascending=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "collapsed": true,
        "id": "Km4ASbdfkd_A",
        "outputId": "533dd04a-78af-454a-8749-d3e91a59b295"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               System  Correctness  \\\n",
              "14  Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-con...         2.48   \n",
              "25  Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-con...         2.30   \n",
              "24  Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-con...         2.28   \n",
              "13  Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-con...         2.22   \n",
              "\n",
              "    Topicality  Fluency      Total  \n",
              "14        4.34     4.76  51.232832  \n",
              "25        4.48     4.62  47.604480  \n",
              "24        4.36     4.54  45.131232  \n",
              "13        3.82     4.72  40.027488  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5e704fa1-2585-4c82-b2fb-b60d5931d061\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>System</th>\n",
              "      <th>Correctness</th>\n",
              "      <th>Topicality</th>\n",
              "      <th>Fluency</th>\n",
              "      <th>Total</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-con...</td>\n",
              "      <td>2.48</td>\n",
              "      <td>4.34</td>\n",
              "      <td>4.76</td>\n",
              "      <td>51.232832</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-con...</td>\n",
              "      <td>2.30</td>\n",
              "      <td>4.48</td>\n",
              "      <td>4.62</td>\n",
              "      <td>47.604480</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-con...</td>\n",
              "      <td>2.28</td>\n",
              "      <td>4.36</td>\n",
              "      <td>4.54</td>\n",
              "      <td>45.131232</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-con...</td>\n",
              "      <td>2.22</td>\n",
              "      <td>3.82</td>\n",
              "      <td>4.72</td>\n",
              "      <td>40.027488</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5e704fa1-2585-4c82-b2fb-b60d5931d061')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5e704fa1-2585-4c82-b2fb-b60d5931d061 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5e704fa1-2585-4c82-b2fb-b60d5931d061');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-3445276f-f5e6-4232-82f6-6efa43667b49\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3445276f-f5e6-4232-82f6-6efa43667b49')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-3445276f-f5e6-4232-82f6-6efa43667b49 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"    ~df_merged[\\\"System\\\"]\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"System\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-continuous-no_head-lora-cthulhu-checkpoint-455-quantized\",\n          \"Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-continuous-lora-cthulhu-checkpoint-450\",\n          \"Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-continuous-no_head-lora-cthulhu-checkpoint-455\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Correctness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.11195237082497773,\n        \"min\": 2.22,\n        \"max\": 2.48,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          2.3,\n          2.22,\n          2.48\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Topicality\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.29325756597230385,\n        \"min\": 3.82,\n        \"max\": 4.48,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          4.48,\n          3.82,\n          4.34\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Fluency\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.09933109617167545,\n        \"min\": 4.54,\n        \"max\": 4.76,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          4.62,\n          4.72,\n          4.76\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Total\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 4.703989098000968,\n        \"min\": 40.027488000000005,\n        \"max\": 51.232831999999995,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          47.60448,\n          40.027488000000005,\n          51.232831999999995\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# show only systems using: (1) combo adapter (2) 8B\n",
        "df_merged[\n",
        "    df_merged[\"System\"].str.contains(\"a32-combo\") &\n",
        "    df_merged[\"System\"].str.contains(\"-8B-\")].sort_values(by=\"Correctness\", ascending=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "collapsed": true,
        "id": "heZdYzInmGjV",
        "outputId": "e9149d5e-4943-4651-80fb-aacf1aa87d9a"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               System  Correctness  \\\n",
              "6   Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-com...         2.20   \n",
              "19  Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-com...         2.14   \n",
              "\n",
              "    Topicality  Fluency     Total  \n",
              "6         4.84     4.72  50.25856  \n",
              "19        4.76     4.80  48.89472  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ce7d6944-c49e-477a-a1c5-ba4d1920c1a7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>System</th>\n",
              "      <th>Correctness</th>\n",
              "      <th>Topicality</th>\n",
              "      <th>Fluency</th>\n",
              "      <th>Total</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-com...</td>\n",
              "      <td>2.20</td>\n",
              "      <td>4.84</td>\n",
              "      <td>4.72</td>\n",
              "      <td>50.25856</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-com...</td>\n",
              "      <td>2.14</td>\n",
              "      <td>4.76</td>\n",
              "      <td>4.80</td>\n",
              "      <td>48.89472</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ce7d6944-c49e-477a-a1c5-ba4d1920c1a7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-ce7d6944-c49e-477a-a1c5-ba4d1920c1a7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-ce7d6944-c49e-477a-a1c5-ba4d1920c1a7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-edb27909-580c-42b0-bbe0-871fa3faa310\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-edb27909-580c-42b0-bbe0-871fa3faa310')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-edb27909-580c-42b0-bbe0-871fa3faa310 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"    df_merged[\\\"System\\\"]\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"System\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-combo-no_head-lora-cthulhu-checkpoint-518-quantized\",\n          \"Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-combo-no_head-lora-cthulhu-checkpoint-518\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Correctness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.04242640687119289,\n        \"min\": 2.14,\n        \"max\": 2.2,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          2.14,\n          2.2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Topicality\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05656854249492385,\n        \"min\": 4.76,\n        \"max\": 4.84,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          4.76,\n          4.84\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Fluency\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.05656854249492385,\n        \"min\": 4.72,\n        \"max\": 4.8,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          4.8,\n          4.72\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Total\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9643805124534582,\n        \"min\": 48.89472,\n        \"max\": 50.258559999999996,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          48.89472,\n          50.258559999999996\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# show only systems using: (1) stacked lora adapter (2) 8B\n",
        "df_merged[\n",
        "    df_merged[\"System\"].str.contains(\"a32-merged\") &\n",
        "    df_merged[\"System\"].str.contains(\"-8B-\") &\n",
        "    ~df_merged[\"System\"].str.contains(\"RAG\")].sort_values(by=\"Correctness\", ascending=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 182
        },
        "collapsed": true,
        "id": "-kh5Vh3pmYRp",
        "outputId": "b8487064-6904-4fd4-d7e2-9f7876a95889"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              System  Correctness  Topicality  \\\n",
              "7  Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-mer...         2.00        4.78   \n",
              "5  Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-mer...         1.98        4.78   \n",
              "\n",
              "   Fluency      Total  \n",
              "7     4.56  43.593600  \n",
              "5     4.58  43.346952  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-be386eaa-0857-4b91-bc4e-39516bde6de1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>System</th>\n",
              "      <th>Correctness</th>\n",
              "      <th>Topicality</th>\n",
              "      <th>Fluency</th>\n",
              "      <th>Total</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-mer...</td>\n",
              "      <td>2.00</td>\n",
              "      <td>4.78</td>\n",
              "      <td>4.56</td>\n",
              "      <td>43.593600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-mer...</td>\n",
              "      <td>1.98</td>\n",
              "      <td>4.78</td>\n",
              "      <td>4.58</td>\n",
              "      <td>43.346952</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-be386eaa-0857-4b91-bc4e-39516bde6de1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-be386eaa-0857-4b91-bc4e-39516bde6de1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-be386eaa-0857-4b91-bc4e-39516bde6de1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-365c74e6-d167-4f9c-b05a-08f7c26c4117\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-365c74e6-d167-4f9c-b05a-08f7c26c4117')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-365c74e6-d167-4f9c-b05a-08f7c26c4117 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"    ~df_merged[\\\"System\\\"]\",\n  \"rows\": 2,\n  \"fields\": [\n    {\n      \"column\": \"System\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-merged_cont-adapter_qa-lora-cthulhu-checkpoint-last\",\n          \"Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-merged_qa-adapter_cont-lora-cthulhu-checkpoint-last\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Correctness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.014142135623730963,\n        \"min\": 1.98,\n        \"max\": 2.0,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1.98,\n          2.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Topicality\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 4.78,\n        \"max\": 4.78,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          4.78\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Fluency\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.014142135623731277,\n        \"min\": 4.56,\n        \"max\": 4.58,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          4.58\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Total\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.17440647336608983,\n        \"min\": 43.34695200000001,\n        \"max\": 43.593599999999995,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          43.34695200000001\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# show only systems using: (1) RAG (2) 8B\n",
        "df_merged[\n",
        "    df_merged[\"System\"].str.contains(\"-8B-\") &\n",
        "    df_merged[\"System\"].str.contains(\"RAG\")].sort_values(by=\"Correctness\", ascending=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "collapsed": true,
        "id": "etkN9k4tmsAL",
        "outputId": "f1c055eb-13fc-44f5-87a2-c0b7097bd6fc"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               System  Correctness  \\\n",
              "22           Llama-3.1-8B-Instruct-RAG-base-quantized         4.04   \n",
              "10                     Llama-3.1-8B-Instruct-RAG-base         4.00   \n",
              "1   Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-con...         3.00   \n",
              "18  Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-mer...         2.60   \n",
              "\n",
              "    Topicality  Fluency     Total  \n",
              "22        4.90     4.96  98.18816  \n",
              "10        4.92     4.96  97.61280  \n",
              "1         4.72     4.74  67.11840  \n",
              "18        4.74     4.00  49.29600  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cfebecbd-9183-491d-aeb3-096834b4ab5a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>System</th>\n",
              "      <th>Correctness</th>\n",
              "      <th>Topicality</th>\n",
              "      <th>Fluency</th>\n",
              "      <th>Total</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>Llama-3.1-8B-Instruct-RAG-base-quantized</td>\n",
              "      <td>4.04</td>\n",
              "      <td>4.90</td>\n",
              "      <td>4.96</td>\n",
              "      <td>98.18816</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Llama-3.1-8B-Instruct-RAG-base</td>\n",
              "      <td>4.00</td>\n",
              "      <td>4.92</td>\n",
              "      <td>4.96</td>\n",
              "      <td>97.61280</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-con...</td>\n",
              "      <td>3.00</td>\n",
              "      <td>4.72</td>\n",
              "      <td>4.74</td>\n",
              "      <td>67.11840</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-mer...</td>\n",
              "      <td>2.60</td>\n",
              "      <td>4.74</td>\n",
              "      <td>4.00</td>\n",
              "      <td>49.29600</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cfebecbd-9183-491d-aeb3-096834b4ab5a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-cfebecbd-9183-491d-aeb3-096834b4ab5a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-cfebecbd-9183-491d-aeb3-096834b4ab5a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-7969aa0e-c807-437f-bd5f-dd1bb668521b\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7969aa0e-c807-437f-bd5f-dd1bb668521b')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-7969aa0e-c807-437f-bd5f-dd1bb668521b button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"    df_merged[\\\"System\\\"]\",\n  \"rows\": 4,\n  \"fields\": [\n    {\n      \"column\": \"System\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Llama-3.1-8B-Instruct-RAG-base\",\n          \"Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-merged_qa-adapter_cont-lora-cthulhu-RAG-checkpoint-last-quantized\",\n          \"Llama-3.1-8B-Instruct-RAG-base-quantized\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Correctness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7232334800509906,\n        \"min\": 2.6,\n        \"max\": 4.04,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          4.0,\n          2.6,\n          4.04\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Topicality\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.10456258094238757,\n        \"min\": 4.72,\n        \"max\": 4.92,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          4.92,\n          4.74,\n          4.9\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Fluency\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.45530209751328843,\n        \"min\": 4.0,\n        \"max\": 4.96,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          4.96,\n          4.74,\n          4.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Total\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 24.045380482213208,\n        \"min\": 49.29600000000001,\n        \"max\": 98.18816000000001,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          97.6128,\n          49.29600000000001,\n          98.18816000000001\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create main summary"
      ],
      "metadata": {
        "id": "5KXLcgM1nZsv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# which systems to retain in the summary and the mapping to their short names\n",
        "\n",
        "system_mappings = {\n",
        "    # base systems\n",
        "    \"Llama-3.2-1B-Instruct-base\": \"base-1B-full\",\n",
        "    \"Llama-3.1-8B-Instruct-base\": \"base-8B-full\",\n",
        "    # qa systems\n",
        "    \"Llama-3.1-8B-Instruct-lr0.0001-b16-r16-a32-lora-cthulhu-best-model\": \"lora-qa-full\",\n",
        "    # cont systems\n",
        "    \"Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-continuous-no_head-lora-cthulhu-checkpoint-455\": \"lora_cont-full\",\n",
        "    \"Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-continuous-lora-cthulhu-checkpoint-450\": \"lora_cont_head-full\",\n",
        "    # combo systems\n",
        "    \"Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-combo-no_head-lora-cthulhu-checkpoint-518\": \"lora_combo-full\",\n",
        "    # stacked systems\n",
        "    \"Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-merged_qa-adapter_cont-lora-cthulhu-checkpoint-last\": \"lora_stack-full\",\n",
        "    # rag systems\n",
        "    \"Llama-3.1-8B-Instruct-RAG-base\": \"base-full-rag\",\n",
        "    \"Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-continuous-lora-cthulhu-RAG-checkpoint-450\": \"lora_cont-full-rag\",\n",
        "    \"Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-merged_qa-adapter_cont-lora-cthulhu-RAG-checkpoint-last-quantized\":\"lora_stack-quan-rag\"\n",
        "}\n",
        "\n",
        "df_merged[df_merged[\"System\"].isin(system_mappings.keys())] \\\n",
        "         .set_index(\"System\") \\\n",
        "         .rename(index=system_mappings) \\\n",
        "         .reset_index() \\\n",
        "         .sort_values(by=\"Correctness\", ascending=False)"
      ],
      "metadata": {
        "id": "4-SuNl8pyz2A",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "collapsed": true,
        "outputId": "6a1e0877-cfe4-47ce-ce59-8a4134826dd6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                System  Correctness  Topicality  Fluency      Total\n",
              "5        base-full-rag         4.00        4.92     4.96  97.612800\n",
              "0   lora_cont-full-rag         3.00        4.72     4.74  67.118400\n",
              "9  lora_stack-quan-rag         2.60        4.74     4.00  49.296000\n",
              "8       lora_cont-full         2.48        4.34     4.76  51.232832\n",
              "4         lora-qa-full         2.34        4.90     4.82  55.266120\n",
              "7  lora_cont_head-full         2.22        3.82     4.72  40.027488\n",
              "2      lora_combo-full         2.20        4.84     4.72  50.258560\n",
              "3      lora_stack-full         2.00        4.78     4.56  43.593600\n",
              "6         base-8B-full         1.44        2.14     4.96  15.284736\n",
              "1         base-1B-full         1.40        2.02     4.84  13.687520"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bb743ee9-5278-488d-a677-7812140266f3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>System</th>\n",
              "      <th>Correctness</th>\n",
              "      <th>Topicality</th>\n",
              "      <th>Fluency</th>\n",
              "      <th>Total</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>base-full-rag</td>\n",
              "      <td>4.00</td>\n",
              "      <td>4.92</td>\n",
              "      <td>4.96</td>\n",
              "      <td>97.612800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>lora_cont-full-rag</td>\n",
              "      <td>3.00</td>\n",
              "      <td>4.72</td>\n",
              "      <td>4.74</td>\n",
              "      <td>67.118400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>lora_stack-quan-rag</td>\n",
              "      <td>2.60</td>\n",
              "      <td>4.74</td>\n",
              "      <td>4.00</td>\n",
              "      <td>49.296000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>lora_cont-full</td>\n",
              "      <td>2.48</td>\n",
              "      <td>4.34</td>\n",
              "      <td>4.76</td>\n",
              "      <td>51.232832</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>lora-qa-full</td>\n",
              "      <td>2.34</td>\n",
              "      <td>4.90</td>\n",
              "      <td>4.82</td>\n",
              "      <td>55.266120</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>lora_cont_head-full</td>\n",
              "      <td>2.22</td>\n",
              "      <td>3.82</td>\n",
              "      <td>4.72</td>\n",
              "      <td>40.027488</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>lora_combo-full</td>\n",
              "      <td>2.20</td>\n",
              "      <td>4.84</td>\n",
              "      <td>4.72</td>\n",
              "      <td>50.258560</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>lora_stack-full</td>\n",
              "      <td>2.00</td>\n",
              "      <td>4.78</td>\n",
              "      <td>4.56</td>\n",
              "      <td>43.593600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>base-8B-full</td>\n",
              "      <td>1.44</td>\n",
              "      <td>2.14</td>\n",
              "      <td>4.96</td>\n",
              "      <td>15.284736</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>base-1B-full</td>\n",
              "      <td>1.40</td>\n",
              "      <td>2.02</td>\n",
              "      <td>4.84</td>\n",
              "      <td>13.687520</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bb743ee9-5278-488d-a677-7812140266f3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-bb743ee9-5278-488d-a677-7812140266f3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-bb743ee9-5278-488d-a677-7812140266f3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-c9c4146f-e9cc-48cf-9074-e7142854851e\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c9c4146f-e9cc-48cf-9074-e7142854851e')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-c9c4146f-e9cc-48cf-9074-e7142854851e button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"         \",\n  \"rows\": 10,\n  \"fields\": [\n    {\n      \"column\": \"System\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 10,\n        \"samples\": [\n          \"base-8B-full\",\n          \"lora_cont-full-rag\",\n          \"lora_cont_head-full\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Correctness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.753787473732189,\n        \"min\": 1.4,\n        \"max\": 4.0,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          1.44,\n          3.0,\n          2.22\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Topicality\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.1262306848756853,\n        \"min\": 2.02,\n        \"max\": 4.92,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          2.14,\n          4.72,\n          3.82\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Fluency\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.2757132165453405,\n        \"min\": 4.0,\n        \"max\": 4.96,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          4.74,\n          4.72,\n          4.96\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Total\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 24.09804629915175,\n        \"min\": 13.68752,\n        \"max\": 97.6128,\n        \"num_unique_values\": 10,\n        \"samples\": [\n          15.284735999999999,\n          67.11840000000001,\n          40.027488000000005\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plot"
      ],
      "metadata": {
        "id": "oqh1eeROpY-3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "fig, axs = plt.subplots(figsize=(20,8))\n",
        "box = df_cor.plot.box(\n",
        "    showmeans=True,\n",
        "    patch_artist=True,\n",
        "    boxprops=dict(facecolor='bisque'),\n",
        "    medianprops=dict(linewidth=3, color='green'),\n",
        "    meanprops=dict(marker='D', color='green'),\n",
        "    ax=axs\n",
        ")\n",
        "axs.tick_params(labelrotation=90)"
      ],
      "metadata": {
        "id": "q-_DZlSK7AQ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# computing statistical significance using Wilconxon test\n",
        "\n",
        "import scipy.stats as stats\n",
        "\n",
        "base_rag_corr = df_cor[\"Llama-3.1-8B-Instruct-RAG-base - Correctness\"].to_list()\n",
        "lora_nohead_corr = df_cor[\"Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-continuous-no_head-lora-cthulhu-checkpoint-455 - Correctness\"]\n",
        "lora_head_corr = df_cor[\"Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-continuous-lora-cthulhu-checkpoint-450 - Correctness\"]\n",
        "#lora_nohead_corr = df_cor[\"Llama-3.2-1B-Instruct-base - Correctness\"]\n",
        "\n",
        "stats.wilcoxon(lora_head_corr, lora_nohead_corr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RueTXGWNBCsX",
        "outputId": "ab08528b-7986-4158-c44c-4829b6f6eb50",
        "collapsed": true
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "WilcoxonResult(statistic=np.float64(61.0), pvalue=np.float64(0.08858881295542467))"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "lora_nohead_topi = df_top[\"Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-continuous-no_head-lora-cthulhu-checkpoint-455 - Topicality\"]\n",
        "lora_head_topi = df_top[\"Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-continuous-lora-cthulhu-checkpoint-450 - Topicality\"]\n",
        "lora_qa_topi = df_top[\"Llama-3.1-8B-Instruct-lr0.0001-b16-r16-a32-lora-cthulhu-best-model - Topicality\"]\n",
        "\n",
        "stats.wilcoxon(lora_head_topi, lora_nohead_topi)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "FQ9ZKnijdGqO",
        "outputId": "7fd3d210-62fb-4cef-e2c1-3db224899742"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "WilcoxonResult(statistic=np.float64(36.0), pvalue=np.float64(0.008487503337192))"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate single example"
      ],
      "metadata": {
        "id": "vITcG6e9qxsW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "messages = [\n",
        "    #{\"role\": \"user\", \"content\": f\"What happens to an investigator at the age of 40?\"},\n",
        "    #{\"role\": \"user\", \"content\": f\"What should you do if a roll doesn't mesh with your character concept?\"},\n",
        "    #{\"role\": \"user\", \"content\": f\"What is the task in the Personal Description section?\"},\n",
        "    #{\"role\": \"user\", \"content\": f\"What is the name of the wife mentioned in the text?\"},\n",
        "    {\"role\": \"user\", \"content\": f\"What is the chance of success if Harvey makes two successive rolls against two different skills?\"},\n",
        "]\n",
        "\n",
        "inputs = tokenizer.apply_chat_template(\n",
        "    messages,\n",
        "    tokenize = True,\n",
        "    add_generation_prompt = True, # Must add for generation\n",
        "    return_tensors = \"pt\",\n",
        ").to(device)\n",
        "\n",
        "print(\"*\"*20)\n",
        "print(\"Tokenized input:\")\n",
        "print(tokenizer.decode(inputs[0]).strip())\n",
        "print(\"*\"*20)\n",
        "print(\"\\nAnswer:\")\n",
        "\n",
        "_ = peft_model.generate(\n",
        "    input_ids=inputs,\n",
        "    pad_token_id=tokenizer.pad_token_id,\n",
        "    streamer = TextStreamer(tokenizer, skip_prompt = True),\n",
        "    max_new_tokens = 256,\n",
        "    temperature = 0.1\n",
        "    )\n",
        "\n"
      ],
      "metadata": {
        "id": "Y-AN94KCNc4S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Utils to check GPU status"
      ],
      "metadata": {
        "id": "5YAMdz21odZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## free the memory again\n",
        "import torch\n",
        "import gc\n",
        "\n",
        "del model\n",
        "del peft_model\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "HXnEUte2zf5m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!  nvidia-smi"
      ],
      "metadata": {
        "collapsed": true,
        "id": "G3-4jketFCHS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! fuser -v /dev/nvidia*"
      ],
      "metadata": {
        "id": "UPMAuQp9Fckf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! kill -9 927"
      ],
      "metadata": {
        "id": "RuOtG3vsFeM6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Old code (deprecated)"
      ],
      "metadata": {
        "id": "x2YujLg5g8cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run automated evaluation\n",
        "\n",
        "   - https://huggingface.co/spaces/evaluate-metric/bleu\n",
        "   - https://huggingface.co/prometheus-eval/prometheus-13b-v1.0\n",
        "\n",
        "Relevant APIs for automated metrics:\n",
        "\n",
        "  - https://github.com/huggingface/evaluate/tree/main/metrics/\n",
        "  - https://huggingface.co/spaces/evaluate-metric/bleu"
      ],
      "metadata": {
        "id": "VX0X_rquqiPC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import evaluate\n",
        "from datasets import load_dataset\n",
        "\n",
        "\n",
        "%cd /content/cthulhu_fine_tuning\n",
        "\n",
        "gt_dataset_file = \"evaluation/evaluation-dataset/cthulhu_eval_dataset.csv\"\n",
        "predictios_dir = \"/content/cthulhu_fine_tuning/evaluation/evaluation-results/*csv\"\n",
        "metric_names = ['meteor', 'bleu', 'rouge']\n",
        "\n",
        "# load metrics\n",
        "metrics = []\n",
        "for metric_name in metric_names:\n",
        "  metrics.append(evaluate.load(metric_name))\n",
        "\n",
        "# load ground truth\n",
        "gt_dataset = load_dataset(\"csv\", data_files=dataset_file, split=\"train\")\n",
        "\n",
        "\n",
        "results = {metric_name:[] for metric_name in metric_names}\n",
        "results[\"system\"] = []\n",
        "\n",
        "# for each system to evaluate\n",
        "for pred_file in glob.glob(predictios_dir):\n",
        "  pred_dataset = load_dataset(\"csv\", data_files=pred_file, split=\"train\")\n",
        "  system_name = pred_file.split(\"/\")[-1]\n",
        "  results[\"system\"].append(system_name)\n",
        "  # for each evaluation metric\n",
        "  for metric in metrics:\n",
        "    # compute metric\n",
        "    score = metric.compute(predictions=pred_dataset['generated_answer'], references=gt_dataset['answer'])\n",
        "    results[metric.name].append(score)\n",
        "\n",
        "print(results)\n"
      ],
      "metadata": {
        "id": "45lr3UniwElb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Other code"
      ],
      "metadata": {
        "id": "YD5c4tDgKkfv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# FUNCTIONS TO GENERATE ANSWERS FROM QUESTIONS IN THE DATASET, AND PUSH RESULTS TO GIT\n",
        "\n",
        "DEFAULT_SYSTEM_PROMPT = \"You are a helpful AI assistant.\"\n",
        "\n",
        "from dataclasses import dataclass\n",
        "\n",
        "@dataclass\n",
        "class Adapter:\n",
        "  name: str\n",
        "  subfolder: str\n",
        "\n",
        "  @property\n",
        "  def shortname(self):\n",
        "    return self.name.replace(\".\", \"_\")\n",
        "\n",
        "\n",
        "def generate_text(target_model, example, temperature=0.1, greedy=False, system_prompt=None):\n",
        "  \"\"\"\n",
        "  Generates the answer based on the question of a given example using a language model.\n",
        "\n",
        "  Args:\n",
        "    example: A dictionary containing the input data, expected to have a \"question\" key.\n",
        "    temperature: The temperature for text generation (default is 0.1).\n",
        "    greedy: Whether to use greedy decoding (default is False).\n",
        "    system_prompt: A system prompt to use for the model (default is \"You are a helpful AI assistant.\").\n",
        "\n",
        "  Returns:\n",
        "    The generated answer as a string.\n",
        "  \"\"\"\n",
        "  # see: https://huggingface.co/docs/datasets/en/process#multiprocessing\n",
        "\n",
        "  if not system_prompt:\n",
        "    system_prompt = DEFAULT_SYSTEM_PROMPT\n",
        "\n",
        "  # format to chatml\n",
        "  chat = [\n",
        "      {\"role\": \"system\", \"content\": f\"{system_prompt}\"},\n",
        "      {\"role\": \"user\", \"content\": f\"{example['question']}\"}\n",
        "  ]\n",
        "  chatml = tokenizer.apply_chat_template(\n",
        "      chat,\n",
        "      tokenize = False,\n",
        "      add_generation_prompt = True\n",
        "  )\n",
        "\n",
        "  # tokenize\n",
        "  inputs = tokenizer(chatml, return_tensors=\"pt\").to(device)\n",
        "  prompt_length = inputs['input_ids'].shape[1]\n",
        "\n",
        "  # generate tokens\n",
        "  with torch.no_grad():\n",
        "    if greedy:\n",
        "      # greedy generation\n",
        "      output_ids = target_model.generate(**inputs, max_new_tokens = 256, do_sample = False, pad_token_id=tokenizer.pad_token_id)\n",
        "    else:\n",
        "      # multinomial sampling generation\n",
        "      output_ids = target_model.generate(**inputs, max_new_tokens = 256, temperature = temperature, pad_token_id=tokenizer.pad_token_id)\n",
        "\n",
        "  # decode generated tokens into text\n",
        "  output_text = tokenizer.decode(output_ids[0][prompt_length:], skip_special_tokens=True) # remove input prompt from output (https://discuss.huggingface.co/t/generate-returns-full-prompt-plus-answer/70453)\n",
        "\n",
        "  return output_text\n",
        "\n",
        "\n",
        "def generate_texts(target_model, dataset, num_examples=3, temperature=0.1, greedy=False):\n",
        "  results = []\n",
        "  ct = 1\n",
        "  for example in dataset:\n",
        "    results.append(generate_text(target_model, example, temperature=temperature, greedy=greedy)) # let's generate using only a bit of creativity (temp=0.1)\n",
        "    if ct == num_examples:\n",
        "      break\n",
        "    ct += 1\n",
        "  return results\n",
        "\n",
        "\n",
        "def evaluate_model_on_dataset(target_model, dataset, temperature=0.1, greedy=False, system_prompt=None):\n",
        "  \"\"\"\n",
        "  Generates the answer for the question in each example in the dataset using the provided model.\n",
        "\n",
        "  Args:\n",
        "    dataset: A Hugging Face Dataset object, containing the questions in the field \"question\".\n",
        "    model: A Hugging Face model for text generation.\n",
        "    temperature: The temperature for text generation (default is 0.1).\n",
        "    greedy: Whether to use greedy decoding (default is False).\n",
        "    system_prompt: A system prompt to use for the model (default is \"You are a helpful AI assistant.\").\n",
        "\n",
        "  Returns:\n",
        "    A Hugging Face Dataset object with an added \"generated_answer\" column.\n",
        "  \"\"\"\n",
        "  generated_texts = []\n",
        "\n",
        "  for ct, example in enumerate(dataset):\n",
        "    print(f\"Generating answer {ct}/{len(dataset)}\")\n",
        "    generated_text = generate_text(target_model, example, temperature=temperature, greedy=greedy, system_prompt=system_prompt)\n",
        "    generated_texts.append(generated_text)\n",
        "\n",
        "  return dataset.add_column(\"generated_answer\", generated_texts)\n",
        "\n",
        "\n",
        "def push_results_to_git(dataset_with_answers, adapter: Adapter, system_prompt=None):\n",
        "  \"\"\"\n",
        "  Pushes evaluation results to the git repository.\n",
        "\n",
        "  Args:\n",
        "    dataset_with_answers: A Hugging Face Dataset object containing the generated answers.\n",
        "    model_name: The name of the model used for generation.\n",
        "  \"\"\"\n",
        "\n",
        "  output_file_name = adapter.name + \"-\" + adapter.subfolder\n",
        "\n",
        "  if not system_prompt:\n",
        "    system_prompt = DEFAULT_SYSTEM_PROMPT\n",
        "\n",
        "  if system_prompt != DEFAULT_SYSTEM_PROMPT:\n",
        "    output_file_name = output_file_name + \"_prompt_\" + str(hash(system_prompt)% 10**6)\n",
        "\n",
        "\n",
        "  output_file = f\"evaluation/evaluation-results-quantized/res_{output_file_name}.csv\"\n",
        "  dataset_with_answers.add_column(\"system_prompt\", [system_prompt for _ in range(len(dataset_with_answers))]) \\\n",
        "    .to_csv(output_file)\n",
        "\n",
        "  ! git config --global user.email \"marco.pennacchiotti@gmail.com\"\n",
        "  ! git add {output_file}\n",
        "  ! git commit -m \"added generated answers\"\n",
        "  ! git push origin main\n"
      ],
      "metadata": {
        "id": "xUetK0-0_f79"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LOAD BASE MODEL FROM HF HUB\n",
        "#https://discuss.huggingface.co/t/model-merging-leads-to-different-output/103986/3\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "from peft import AutoPeftModelForCausalLM, PeftModel\n",
        "\n",
        "namespace=\"mpenna77\"\n",
        "base_model_name =  \"meta-llama/Llama-3.1-8B-Instruct\" # \"meta-llama/Llama-3.2-1B-Instruct\"\n",
        "\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,                     # weights stored in 4 bits (saves memory)\n",
        "    bnb_4bit_quant_type=\"nf4\",             # format used for storing in 4 bits\n",
        "    bnb_4bit_use_double_quant=True,        # double quantize (saves memory)\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16, # perform operations in 16bit instead of 32bit (speed up fine-tuning)\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(base_model_name, padding_side=\"left\", use_fast=True)\n",
        "model = AutoModelForCausalLM.from_pretrained(base_model_name, quantization_config=bnb_config).eval().to(device)"
      ],
      "metadata": {
        "id": "-Trz0jIMjnyL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LOAD PEFT MODEL\n",
        "\n",
        "#peft_model_name = \"Llama-3.1-8B-Instruct-lr0.0001-b32-r64-a32-continuous-lora-cthulhu\"\n",
        "#peft_model_checkpoint = \"checkpoint-450\"\n",
        "\n",
        "#peft_model_name = \"Llama-3.1-8B-Instruct-lr0.0001-b16-r16-a32-lora-cthulhu\"\n",
        "#peft_model_checkpoint = \"checkpoint-2127\"\n",
        "\n",
        "#peft_model_name = \"Llama-3.1-8B-Instruct-lr0.0001-b16-r16-a32-lora-cthulhu\"\n",
        "#peft_model_checkpoint = \"best-model\"\n",
        "\n",
        "#peft_model_name = \"Llama-3.1-8B-Instruct-lr3e-05-b32-r16-a32-lora-cthulhu\"\n",
        "#peft_model_checkpoint = \"checkpoint-1420\"\n",
        "\n",
        "#peft_model_name = \"Llama-3.1-8B-Instruct-lr3e-05-b32-r16-a32-lora-cthulhu\"\n",
        "#peft_model_checkpoint = \"best-model\"\n",
        "\n",
        "#peft_model_name = \"Llama-3.2-1B-Instruct-lr0.0001-b64-r16-a32-lora-cthulhu\"\n",
        "#peft_model_checkpoint = \"best-model\"\n",
        "\n",
        "peft_model_name = \"Llama-3.1-8B-Instruct-lr0.0001-b16-r64-a32-lora-cthulhu\"\n",
        "peft_model_checkpoint = \"checkpoint-2127\"\n",
        "\n",
        "peft_model = PeftModel.from_pretrained(\n",
        "    model,\n",
        "    f\"{namespace}/{peft_model_name}\",\n",
        "    subfolder=peft_model_checkpoint).eval().to(device)\n",
        "\n",
        "#peft_model = AutoPeftModelForCausalLM.from_pretrained(f\"{namespace}/{model_name}\").eval().to(device)"
      ],
      "metadata": {
        "id": "qVNiSohSdcXQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GENERATE ANSWERS FROM DATASET, PUSH RESULTS TO GIT\n",
        "\n",
        "system_prompt = None\n",
        "\n",
        "# let's generate using only a bit of creativity (temp=0.1)\n",
        "dataset_with_answers = evaluate_model_on_dataset(dataset, temperature=0.1, greedy=False, system_prompt=system_prompt)\n",
        "push_results_to_git(dataset_with_answers, system_prompt=system_prompt)\n",
        "\n"
      ],
      "metadata": {
        "id": "OBYwN67pdgwv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load models\n",
        "\n",
        "\"\"\"\n",
        "model_info = (\n",
        "        \"Llama-3.2-1B-Instruct-lr0.0001-b64-r16-a32-lora-cthulhu-checkpoint-2127\",\n",
        "        \"meta-llama/Llama-3.1-8B-Instruct\",\n",
        "        \"/content/cthulhu_fine_tuning/fine-tuning/models/Llama-3.1-8B-Instruct-lr0.0001-b16-r16-a32-lora-cthulhu/checkpoint-2127\"\n",
        "        )\n",
        "\n",
        "model_info = (\n",
        "        \"Llama-3.2-1B-Instruct-lr0.0001-b64-r16-a32-lora-cthulhu\",\n",
        "        \"meta-llama/Llama-3.2-1B-Instruct\",\n",
        "        \"/content/cthulhu_fine_tuning/fine-tuning/models/Llama-3.2-1B-Instruct-lr0.0001-b64-r16-a32-lora-cthulhu/best-model\"\n",
        "        )\n",
        "\n",
        "model_info = (\n",
        "        \"Llama-3.2-1B-Instruct-lr0.0001-b64-r16-a32-lora-cthulhu-best-model\",\n",
        "        \"meta-llama/Llama-3.1-8B-Instruct\",\n",
        "        \"/content/cthulhu_fine_tuning/fine-tuning/models/Llama-3.1-8B-Instruct-lr0.0001-b16-r16-a32-lora-cthulhu/best-model\"\n",
        "        )\n",
        "\"\"\"\n",
        "model_info =     (\n",
        "        \"Llama-3.1-8B-Instruct-lr3e-05-b32-r16-a32-lora-cthulhu-checkpoint-1420\",\n",
        "        \"meta-llama/Llama-3.1-8B-Instruct\",\n",
        "        \"/content/cthulhu_fine_tuning/fine-tuning/models/Llama-3.1-8B-Instruct-lr3e-05-b32-r16-a32-lora-cthulhu/checkpoint-1420\"\n",
        "    )\n"
      ],
      "metadata": {
        "id": "uNJdcbxLSlp2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# USE THIS IF MODEL WAS SAVED IN GITHUB\n",
        "\n",
        "# Load model:\n",
        "# 0. Load tokenizer\n",
        "# 1. Load the base model\n",
        "# 2. Load PEFT config\n",
        "# 3. Load LoRA PEFT model on top of the base model\n",
        "# 4. Move to GPU\n",
        "\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import torch\n",
        "from transformers import BitsAndBytesConfig\n",
        "from peft import PeftConfig, PeftModelForCausalLM, PeftModel\n",
        "\n",
        "model_name = model_info[1]\n",
        "model_dir = model_info[2]\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "\n",
        "# Load tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, padding_side=\"left\", use_fast=True)\n",
        "\n",
        "# Load model\n",
        "#   see:\n",
        "#   https://ai.google.dev/gemma/docs/core/huggingface_text_finetune_qlora\n",
        "#   https://huggingface.co/docs/peft/tutorial/peft_model_config\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,                     # weights stored in 4 bits (saves memory)\n",
        "    bnb_4bit_quant_type=\"nf4\",             # format used for storing in 4 bits\n",
        "    bnb_4bit_use_double_quant=True,        # double quantize (saves memory)\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16, # perform operations in 16bit instead of 32bit (speed up fine-tuning)\n",
        ")\n",
        "\n",
        "# loads model in eval() mode. This means that stuff like batch norm and dropout are not applied (like it would be during training).\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name, quantization_config=bnb_config).eval().to(device)\n",
        "peft_config = PeftConfig.from_pretrained(model_dir)\n",
        "peft_model = PeftModel.from_pretrained(model, model_dir)\n",
        "\n",
        "tokenizer.add_special_tokens({\"pad_token\": \"<|finetune_right_pad_id|>\"})\n",
        "model.config.pad_token_id = tokenizer.pad_token_id"
      ],
      "metadata": {
        "id": "HuTrKZuHSQah"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# this code is used to evaluate different generation temperatures for non-greedy\n",
        "# generation. For each temperature, run generation 3 times\n",
        "# Also greedy generation is then run\n",
        "\n",
        "max = 8\n",
        "examples = [[] for x in range(max+1)]\n",
        "\n",
        "for temperature in [0.1, 1.0]:\n",
        "  print(f\"Temperature: {temperature}\")\n",
        "  for run in range(3):\n",
        "    print(f\"  Run: {run}\")\n",
        "    for ct, example in enumerate(dataset):\n",
        "        print(f\"    Example: {ct}\")\n",
        "        examples[ct].append((generate_text(example, temperature=temperature), temperature, ct, example[\"question\"]))\n",
        "        if ct == max:\n",
        "          break\n",
        "print(f\"greedy\")\n",
        "for run in range(3):\n",
        "    print(f\"  Run: {run}\")\n",
        "    for ct, example in enumerate(dataset):\n",
        "        print(f\"    Example: {ct}\")\n",
        "        examples[ct].append((generate_text(example, greedy=True), \"greedy\", ct, example[\"question\"]))\n",
        "        if ct == max:\n",
        "          break\n",
        "\n",
        "for lista in examples:\n",
        "  for example in lista:\n",
        "        print(example)\n",
        "  print(\"*\"*20)"
      ],
      "metadata": {
        "id": "mz1DNsIrsyAx",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# THE FOLLOWING DOES NOT WORK, CAUSE OOM ON MAIN MEM\n",
        "\n",
        "#dataset_with_answers = dataset.map(\n",
        "#    generate_text,\n",
        "#    fn_kwargs={\"model\": model, \"tokenizer\": tokenizer},\n",
        "    #cache_file_name='temp', # see: https://discuss.huggingface.co/t/how-to-load-this-simple-audio-data-set-and-use-dataset-map-without-memory-issues/17722/7\n",
        "#)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "lTP2A3aSgT5O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LOAD DATASET AS CSV\n",
        "import csv\n",
        "\n",
        "%cd /content/cthulhu_fine_tuning\n",
        "\n",
        "with open(\"./eval-data/cthulhu_eval_dataset.csv\") as f:\n",
        "  reader = csv.DictReader(f)\n",
        "  eval_dataset = [row for row in reader]\n",
        "\n",
        "print(f\"Dataset size: {len(eval_dataset)}\")"
      ],
      "metadata": {
        "id": "4b-1JCUJgeGY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def format_to_chatml(example):\n",
        "     return {\n",
        "          \"messages\": [\n",
        "            {\"role\": \"system\", \"content\": f\"You are a helpful AI assistant.\"},\n",
        "            {\"role\": \"user\", \"content\": f\"{example['question']}\"},\n",
        "          ],\n",
        "     }\n",
        "\n",
        "def tokenize(example, tokenizer):\n",
        "    input_ids = tokenizer.apply_chat_template(\n",
        "        example[\"messages\"],\n",
        "        tokenize = True,\n",
        "        padding = True,\n",
        "        truncation = True,\n",
        "        max_length = 256,\n",
        "        add_generation_prompt = True,\n",
        "        return_tensors = \"pt\"\n",
        "    )\n",
        "    return {\"input_ids\": input_ids}\n",
        "\n",
        "\n",
        "\n",
        "tokenizer.add_special_tokens({\"pad_token\": \"<|finetune_right_pad_id|>\"})\n",
        "model.config.pad_token_id = tokenizer.pad_token_id\n",
        "tokenizer.padding_side = 'left'\n",
        "\n",
        "\n",
        "dataset = dataset.map(\n",
        "    format_to_chatml,\n",
        "    remove_columns=dataset.column_names\n",
        ")\n",
        "\n",
        "\n",
        "dataset_tokenized = dataset.map(\n",
        "    tokenize,\n",
        "    #batched=True,\n",
        "    remove_columns=[\"messages\"],\n",
        "    fn_kwargs={\"tokenizer\": tokenizer}\n",
        ")\n",
        "\n",
        "\n",
        "print(dataset[0])\n",
        "print(dataset_tokenized[0])\n"
      ],
      "metadata": {
        "id": "WWuUxPphKIzy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(dataset_tokenized[0][\"input_ids\"][0])"
      ],
      "metadata": {
        "id": "FSWE2qxabk2v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset[0])\n",
        "tokenized_with_template = tokenize(dataset[0], tokenizer)[\"input_ids\"].to(device)\n",
        "print(tokenized_with_template)\n",
        "print(type(tokenized_with_template))\n",
        "\n",
        "tokenized = tokenizer(str(dataset[0]), return_tensors=\"pt\").to(device)\n",
        "print(tokenized)\n",
        "print(type(tokenized))"
      ],
      "metadata": {
        "id": "s3qs5eLBWYYD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "for model, base_model, model_dir in model_infos:\n",
        "  tokenizer = AutoTokenizer.from_pretrained(base_model)\n",
        "  model = AutoModelForCausalLM.from_pretrained(model_dir).to(device)\n",
        "\n",
        "  # prepare eval dataset:\n",
        "\n",
        "  for example in eval_dataset:\n",
        "    chat = [\n",
        "      {\"role\": \"system\", \"content\": f\"You are a helpful AI assistant.\"},\n",
        "      {\"role\": \"user\", \"content\": f\"{example['question']}\"},\n",
        "    ]\n",
        "  inputs = tokenizer.apply_chat_template(chat, tokenize = True, add_generation_prompt = True)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NjrwblNNVy29"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from transformers import AutoTokenizer\n",
        "from pathlib import Path\n",
        "\n",
        "print(MODELS_DIR[2][1])\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODELS_DIR[2][1])"
      ],
      "metadata": {
        "id": "4YVodYC2J8lC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_dataset[0]"
      ],
      "metadata": {
        "id": "Ti8DK2DOMXS4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TextStreamer\n",
        "\n",
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": f\"{eval_dataset[5]['question']}\"},\n",
        "]\n",
        "\n",
        "inputs = tokenizer.apply_chat_template(\n",
        "    messages,\n",
        "    tokenize = True,\n",
        "    add_generation_prompt = True, # Must add for generation\n",
        "    return_tensors = \"pt\",\n",
        ").to(device)\n",
        "\n",
        "print(\"*\"*20)\n",
        "print(\"Tokenized input:\")\n",
        "print(tokenizer.decode(inputs[0]).strip())\n",
        "print(\"*\"*20)\n",
        "print(\"\\nAnswer:\")\n",
        "\n",
        "_ = model.generate(\n",
        "    input_ids=inputs,\n",
        "    pad_token_id=tokenizer.pad_token_id,\n",
        "    streamer = TextStreamer(tokenizer, skip_prompt = True),\n",
        "    max_new_tokens = 256,\n",
        "    temperature = 0.1\n",
        "    )"
      ],
      "metadata": {
        "id": "ccT1FSHRJtdc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}