{
  "best_global_step": 250,
  "best_metric": 0.790784478187561,
  "best_model_checkpoint": "fine-tuning/models/Llama-3.1-8B-Instruct-lr0.0001-b16-r16-a32-lora-cthulhu-cut159/checkpoint-250",
  "epoch": 3.0,
  "eval_steps": 250,
  "global_step": 627,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 1.1961722488038278,
      "grad_norm": 2.03523850440979,
      "learning_rate": 6.352941176470588e-05,
      "loss": 0.9636,
      "step": 250
    },
    {
      "epoch": 1.1961722488038278,
      "eval_loss": 0.790784478187561,
      "eval_runtime": 14.6288,
      "eval_samples_per_second": 12.031,
      "eval_steps_per_second": 0.752,
      "step": 250
    },
    {
      "epoch": 2.3923444976076556,
      "grad_norm": 2.258441925048828,
      "learning_rate": 2.151260504201681e-05,
      "loss": 0.5156,
      "step": 500
    },
    {
      "epoch": 2.3923444976076556,
      "eval_loss": 0.8216502666473389,
      "eval_runtime": 14.6394,
      "eval_samples_per_second": 12.022,
      "eval_steps_per_second": 0.751,
      "step": 500
    }
  ],
  "logging_steps": 250,
  "max_steps": 627,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 250,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 3.987499249277338e+16,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
